# Sylar 从零开发笔记

## 项目初始化 (2026-02-03)
- 编译器: GCC 13.3.0
- 构建工具: CMake 3.28.3
- 目录结构: 采用模块化设计 (base, concurrency, fiber, net, http, log)。

---

## 日志模块 (Log Module)

### 1. LogLevel (日志级别)
#### 类作用
统一管理日志的紧急程度（DEBUG/INFO/WARN/ERROR/FATAL）。它负责将抽象的级别枚举与可读的字符串进行相互转换，为日志系统的过滤功能提供判断标准。

#### 设计理念
定义日志的严重程度，用于后续的过滤控制（如只打印 ERROR 级别以上的日志）。

#### 设计要点
- 采用 `DEBUG < INFO < WARN < ERROR < FATAL` 的递增数值逻辑。

#### 技巧
- 使用宏 (Macro) `XX(name)` 配合 `#name` 字符串化，极大地减少了枚举与字符串相互转换的代码量。

#### 遇到的问题
##### Q: 为什么不使用 `enum class`?
**A**: 虽然 `enum class` (强类型枚举) 更安全，但在日志系统中，我们经常需要把日志级别 and 整数阈值进行比较（例如 `if (current_level >= limit_level)`）。如果使用 `enum class`，每次比较都需要显式强转 `static_cast<int>(level)`，代码会显得非常啰嗦。而普通的 `enum` 支持隐式转换为整型，且我们将 `enum` 包裹在 `class LogLevel` 内部，已经起到了良好的作用域隔离效果。

---

### 2. LogEvent (日志现场)
#### 类作用
“案发现场的档案袋”。它在日志触发的一瞬间，自动抓取并封装所有上下文信息：包括文件名、行号、时间戳、线程ID、协程ID、线程名称以及用户输入的日志内容。

#### 设计理念
“案发现场的档案袋”。在日志发生的那一瞬间，抓取并封装所有相关信息（文件名、行号、时间戳、线程/协程ID、日志内容）。

#### 设计要点
- 使用 `std::stringstream` 提供流式输入支持，使得日志打印像 `std::cout` 一样方便。
- 统一使用 `typedef std::shared_ptr<LogEvent> ptr;` 进行内存管理。

#### 遇到的问题
##### Q: 为什么 `LogEvent` 要持有 `Logger` 的指针？
**A**: 为了实现上下文传递。
1. **格式化需求**: 某些格式化项（如 `%c`）需要打印 Logger 的名称，`LogEvent` 必须知道自己是由谁产生的才能提供这个信息。
2. **高级路由**: 在复杂的日志系统中，可能存在全局的拦截器或钩子。持有 Logger 指针可以让拦截器知道日志的来源模块（是 "system" 还是 "business"），从而进行分流处理（例如将核心模块的日志额外发送到监控告警系统）。

---

### 3. LogFormatter (格式化器)
#### 类作用
“日志的化妆师”。它负责解析用户定义的格式模式（Pattern，如 `%d{%Y-%m-%d} %p %m%n`），并将其转化为具体的输出项（FormatItem），最终将结构化的 `LogEvent` 渲染成特定格式的字符串。

#### 设计理念
负责将结构化的 `LogEvent` 转换为人类可读的字符串。支持用户自定义格式（Pattern）。

#### 设计要点
- **组合模式**: 将复杂的 pattern (如 `%d %m %n`) 拆解为多个独立的 `FormatItem` 子类。
- **多态应用**: `LogFormatter` 持有 `vector<FormatItem::ptr>`，遍历调用虚函数 `format`，实现高度可定制的日志格式。

#### 遇到的问题
##### Q: 如何解决 LogFormatter 和 Logger 的循环引用？
**A**: 这是一个经典的依赖死锁问题：`LogFormatter` 里的 `%c` 需要调用 `Logger` 的方法，而 `Logger` 又包含 `LogFormatter` 成员。
**解决方法**: 使用**前置声明 (Forward Declaration)**。
在 `.h` 头文件中，我们只声明 `class Logger;`，这告诉编译器“有一个叫 Logger 的类”，但不涉及它具体的内存布局或方法。这允许我们在头文件中定义 `shared_ptr<Logger>`。具体的 `#include "logger.h"` 延迟到 `.cc` 实现文件中才进行，从而打破编译时的头文件包含循环。

##### Q: 为什么父类析构函数必须是虚函数 (`virtual`)？
**A**: 这是一个 C++ 内存管理的铁律。
当我们在容器中存储基类指针（`FormatItem::ptr`），但实际指向子类对象（`MessageFormatItem`）时，如果我们销毁这个容器，会调用 `delete` 基类指针。
- 如果析构函数**不是**虚函数：编译器只会静态绑定调用基类 `~FormatItem()`，子类的析构函数完全不会执行，子类特有的资源（如果有）就会泄漏。
- 如果析构函数**是**虚函数：编译器会动态绑定，先调用子类析构，再调用基类析构，确保对象被完整清理。

##### Q: `auto& i : m_items` 中的 `&` 作用？
**A**: 这里的 `&` 表示引用。`m_items` 存储的是 `shared_ptr`。
- 如果不加 `&`：每次循环都会触发 `shared_ptr` 的拷贝构造函数，导致原子引用计数频繁 `+1` 和 `-1`，这虽然是线程安全的，但有微小的性能开销。
- 加上 `&`：`i` 只是该元素的别名，完全没有拷贝开销。

##### Q: `init` 解析逻辑是怎么工作的？
**A**: 本质是一个词法分析状态机。
刻画了模式串，维护一个状态位 `fmt_status`：
- **状态 0 (普通模式)**: 逐个字符读取。如果遇到 `%`，进入解析模式；否则当作普通字符串。
- **状态 1 (格式模式)**: 识别 `%d` 这样的指令。如果遇到 `{`，说明有参数（如日期格式），进入参数提取阶段；如果遇到非字母，说明指令结束，创建对应的 Item。

---

### 4. LogAppender (输出地)
#### 类作用
决定日志“去哪儿”。它是一个抽象基类，通过派生出 `StdoutLogAppender` (控制台) 和 `FileLogAppender` (文件) 等，实现了日志输出渠道的多样化和可扩展性。

#### 设计理念
决定日志的去向（控制台、文件、网络等）。

#### 设计要点
- **线程安全**: 核心成员变量 `std::mutex m_mutex`。
- **独立锁**: 每个 Appender 实例拥有独立的锁，不同文件输出可并行，同一文件输出需排队。

#### 遇到的问题
##### Q: 锁 (Mutex) 到底锁住了什么？
**A**: 锁住的是 **“临界区 (Critical Section)”** 的访问权。
在我们的代码中，临界区就是“往流里写数据”的那几行代码。当一个线程获得了锁，其他线程就必须挂起等待。这保证了**操作的原子性**：即一条日志的输出过程（时间+级别+内容+换行）是连续的，绝对不会被其他线程的日志内容“插队”打断，防止输出乱码。

##### Q: 两个 Logger 同时输出到控制台会乱吗？
**A**: 会。
因为 `std::cout` 是全局唯一的资源。如果 Logger A 和 Logger B 各自拥有一个 `StdoutLogAppender` 实例，它们就会各自拥有一把独立的锁。线程 A 拿着 Lock A 写 `cout`，线程 B 拿着 Lock B 写 `cout` —— 两把锁互不干扰，导致两个线程同时往 `cout` 写东西，输出内容就会交错。
**解决思路**: 让所有 Logger 共享**同一个** `StdoutLogAppender` 实例（单例模式）。这样大家抢的都是同一把锁，就能完美排队了。

---

### 5. Logger (日志器)
#### 类作用
日志系统的核心入口和组装者。它负责持有多个 Appender 和一个 Formatter，根据设定的日志级别进行过滤，并将满足条件的日志分发给所有输出端执行。

#### 设计理念
日志系统的入口和组装者。它负责将 Appender、Formatter、Level 组合在一起，对外提供统一的接口。

#### 设计要点
- **继承 `enable_shared_from_this`**: 允许在成员函数中安全地获取自身的 `shared_ptr`。
- **默认兜底机制**: 包含 `m_root` (根日志器)。如果当前 Logger 没有配置 Appender，可以委托给 Root Logger 输出，防止日志丢失。
- **单例 Manager**: 使用 `LoggerManager` 全局管理所有 Logger，确保相同名称的 Logger 在系统中是同一个实例。

#### 遇到的问题
##### Q: 为什么要继承 `std::enable_shared_from_this`？
**A**: 为了解决 **Double Free (双重释放)** 问题。
在 `Logger::log` 方法中，我们需要创建一个 `LogEvent`，而 `LogEvent` 的构造函数需要一个 `Logger::ptr` (即 `shared_ptr<Logger>`) 来记录是谁产生了日志。
- **错误做法**: `new LogEvent(std::shared_ptr<Logger>(this), ...)`。这会创建一个**全新的引用计数控制块**。当外部持有的 `logger` 指针析构时会 delete 一次，这个临时的 `shared_ptr` 析构时又会 delete 一次，导致程序崩溃。
- **正确做法**: `new LogEvent(shared_from_this(), ...)`。`enable_shared_from_this` 内部维护了一个弱引用 (`weak_ptr`)，指向最初创建该对象的 `shared_ptr` 控制块。调用 `shared_from_this()` 会安全地从这个弱引用提升出一个新的 `shared_ptr`，共享同一个引用计数。
**前提**: 对象必须是通过 `std::make_shared` 或 `std::shared_ptr` 创建的，否则调用该方法会抛异常。

##### Q: Logger 里的互斥锁保护的是什么？
**A**: 保护的是 **Logger 自身的结构配置（成员变量）**。
- **主要保护对象**: `m_appenders` 列表。如果在线程 A 遍历列表写日志时，线程 B 调用了 `addAppender` 修改了列表，会导致迭代器失效，引发程序崩溃。
- **保护范围**: 凡是涉及修改 Logger 私有成员（如 `m_level`, `m_formatter`, `m_appenders`）的操作，以及需要读取 these 成员并进行后续逻辑的操作（如 `log` 过程中的遍历），都必须加锁。
- **区分**: `Appender` 里的锁是保护“输出过程”不被打断；而 `Logger` 里的锁是保护“配置结构”不被破坏。

##### Q: `m_root.reset(new Logger)` 中的 `reset` 是什么意思？
**A**: `reset` 是 `std::shared_ptr` 的一个成员方法。
- **作用**: 重新设置智能指针所指向的对象。它会先让旧对象的引用计数 `-1`（若减至 0 则释放旧对象），然后接管新 `new` 出来的对象的生命周期。
- **原因**: 智能指针出于安全考虑，禁止了从裸指针到智能指针的隐式转换。因此不能直接写 `m_root = new Logger`，必须使用 `reset()` 方法或 `m_root = std::shared_ptr<Logger>(new Logger)`。
- **实践**: 在 `LoggerManager` 的构造函数中使用 `reset` 来初始化全局根日志器。

##### Q: 为什么要设计 `LogEventWrap`？如何实现流式宏打印？
**A**: 为了实现 `SYLAR_LOG_INFO(logger) << "msg"` 这种极其简洁的语法，我们利用了 **RAII (资源获取即初始化)** 和 **临时对象析构** 的特性。

**宏展开解析**：
```cpp
// 原始宏
#define SYLAR_LOG_LEVEL(logger, level) \
    if(logger->getLevel() <= level) \
        sylar::LogEventWrap(sylar::LogEvent::ptr(new sylar::LogEvent(...))).getSS()

// 调用代码
SYLAR_LOG_INFO(logger) << "hello";

// 展开后的实际执行流程
if(logger->getLevel() <= level) { // 1. 级别判断
    sylar::LogEvent::ptr event(new sylar::LogEvent(...)); // 2. 创建事件
    sylar::LogEventWrap wrap(event); // 3. 创建临时包装对象
    wrap.getSS() << "hello"; // 4. 往流里写数据
} // 5. 语句结束，wrap 对象析构
```

**执行步骤详解**：
1. **级别判断 (Check)**: 先判断级别，如果不满足直接跳过，避免了后续所有开销（性能关键）。
2. **创建包装 (Construct)**: 创建一个临时的 `LogEventWrap` 对象。
3. **流式写入 (Stream)**: `getSS()` 返回 `stringstream`，用户通过 `<<` 写入内容。
4. **自动提交 (Destruct & Submit)**: 当这一行代码执行完毕，临时的 `wrap` 对象离开作用域被销毁。**在其析构函数中**，会自动调用 `logger->log(event)` 将日志真正提交。

**结果**: 实现了“写完即触发”的丝滑体验，且用户无需手动调用任何发送函数。

##### Q: 宏 `SYLAR_LOG_ROOT()` 是如何工作的？
**A**: 它是一个便捷宏，底层封装了对 `LoggerManager` 单例的调用。
- 展开前: `SYLAR_LOG_ROOT()`
- 展开后: `sylar::LoggerMgr::GetInstance()->getRoot()`
这隐藏了复杂的单例获取逻辑，让用户感觉像是直接获取了一个全局变量。同理，`SYLAR_LOG_NAME(name)` 封装了 `getLogger(name)`。

---

## 基础模块 (Base Module)

### 1. Util (通用工具类)
#### 模块作用
提供跨平台的底层系统封装，包括获取线程ID、协程ID、获取函数调用堆栈（Backtrace）以及符号解析（Demangle）等，为全系统提供底层支撑。

#### 设计理念
提供系统底层的封装，主要用于获取运行时信息（线程ID、堆栈信息等），为其他模块（如日志、协程、配置）提供基础支撑。

#### 设计要点
- **GetThreadId**: 封装 `syscall(SYS_gettid)`。
- **Backtrace**: 利用 `<execinfo.h>` 库提供的 `backtrace` 和 `backtrace_symbols` 函数获取函数调用栈。
- **Demangle**: 编译器在生成符号时会进行名字修饰（Name Mangling），使用 `abi::__cxa_demangle` 将丑陋的机器符号转换回人类可读的 C++ 函数名。

#### 技巧
- **符号提取**: `backtrace_symbols` 返回的字符串包含 `文件名(函数名+偏移量) [地址]`。通过字符串解析提取出 `函数名` 部分再进行 demangle，可以获得最清晰的堆栈输出。

#### 遇到的问题
##### Q: 为什么 `GetThreadId` 不使用 `pthread_self()`?
**A**: `pthread_self()` 返回的是 POSIX 线程库内部维护的线程 ID（通常是一个很大的内存地址），它在进程内唯一，但在不同进程间不直观。而 `SYS_gettid` 返回的是 Linux 内核分配的真实线程 ID（PID），在 `top` 或 `ps` 命令中能直接看到，更利于调试。

##### Q: 为什么日志输出中会出现 `<<error_format %N>>`?
**A**: 这是因为在 `Logger` 的默认格式模板中使用了 `%N`（线程名称），但在 `LogFormatter` 的映射表中漏掉了该指令的注册。
**解决**: 
1. 在 `LogEvent` 中增加 `m_threadName` 成员。
2. 实现 `ThreadNameFormatItem` 类。

---

### 2. Config (配置模块)
#### 类作用
系统的“神经中枢”。实现“约定优于配置”的设计思想，负责全局配置参数的存储、解析、动态更新以及变更回调通知。支持从 YAML 文件加载及复杂 STL 容器的自动转换。

#### 设计理念
实现“约定优于配置”的设计思想。支持类型安全、复杂容器支持以及配置变更的回调通知（热更新）。

#### 设计要点
- **ConfigVarBase**: 非模板基类，用于统一管理不同类型的配置项（存入同一个 Map）。
- **ConfigVar<T>**: 模板子类，负责存储实际值并处理序列化/反序列化。
- **LexicalCast**: 类型转换中心。通过**模板偏特化**支持基础类型与 YAML 字符串之间的自动转换。
- **变更回调**: 每个 `ConfigVar` 持有一个回调函数列表，当 `setValue` 被调用时触发，实现热加载。

#### 技巧
- **静态初始化保护**: 使用 `GetDatas()` 函数内的静态变量来存储配置 Map，避免了 C++ 全局静态变量初始化顺序不确定的坑 (Static Initialization Order Fiasco)。

#### 遇到的问题
##### Q: 为什么 `LexicalCast` 需要针对 STL 容器进行大量特化？
**A**: 因为 `boost::lexical_cast` 默认只支持基础类型（如 int 转 string）。为了让配置系统支持 `vector<int>`, `map<string, int>` 等复杂结构，我们必须利用**模板偏特化**技术。
- **序列化流程**: 容器 (如 `vector<T>`) -> 遍历并转换每个元素为 YAML 节点 -> 将整个 YAML 节点转为字符串。
- **反序列化流程**: 字符串 -> `YAML::Load` 解析为节点 -> 遍历 YAML 节点并利用 `LexicalCast<string, T>` 转换每个元素 -> 塞回容器。
通过这种递归调用（`LexicalCast` 内部调用 `LexicalCast`），我们甚至可以支持嵌套容器，如 `vector<list<int>>`。

##### Q: 在 Lookup 查找配置时，为什么要用 `dynamic_pointer_cast`?
**A**: 全局 Map 存储的是父类 `ConfigVarBase::ptr`。获取配置时，必须确认其实际类型与用户请求的类型 `T` 一致。`dynamic_pointer_cast` 提供了运行时的类型安全检查。

##### Q: 如何实现从复杂的 YAML 文件批量加载配置？
**A**: 采用了 **“树形结构扁平化”** 的策略。
1. **递归遍历**: 实现辅助函数 `ListAllMember`，递归遍历 YAML 树。
2. **路径拼接**: 将嵌套的结构转换为点分隔的路径字符串（如 `system -> port` 转换为 `system.port`）。
3. **节点存储**: 将所有叶子节点及其对应的完整路径存入一个 `std::list` 中。
4. **统一更新**: 遍历该列表，在 `ConfigVarMap` 中按路径名查找配置项。若匹配成功，则调用 `fromString` 利用之前特化的 `LexicalCast` 进行自动类型转换并赋值。

##### Q: 配置变更回调（Listener）的 ID 为什么用 `static` 变量？
**A**: 为了保证每个监听器在注册时都能获得一个唯一的编号（Key），以便后续可以精准地删除某个特定的监听器（`delListener`）。使用静态变量可以实现自增 ID 的分配。

##### Q: 为什么设置了回调就能实现“热加载”？
**A**: 回调函数本身只是热加载流程的**最后一环**。完整的热加载机制如下：
1. **文件监控 (File Watcher)**: 系统后台有一个线程或定时任务（利用 `inotify` 或 `stat`）监控配置文件（如 `conf.yml`）的修改时间。
2. **触发重载 (Trigger Reload)**: 一旦检测到文件变化，程序自动读取新文件内容。
3. **解析更新 (Parse & Update)**: 调用 `Config::LoadFromYaml`，将新配置解析为内存对象，并调用对应 `ConfigVar` 的 `setValue()` 方法。
4. **变更通知 (Notification)**: `setValue()` 内部检测到值发生变化，遍历 `m_cbs` 列表，依次执行注册的回调函数。
5. **业务响应 (Reaction)**: 回调函数执行具体的业务逻辑（如重置数据库连接池、重启 Listener），从而完成“热更新”。
目前我们实现了 3, 4, 5 步，第 1, 2 步将在后续的文件监控模块中实现。

---

### 3. Noncopyable (不可拷贝基类)
#### 类作用
系统的“安全锁”。通过禁用拷贝构造函数和赋值运算符，强制要求继承该类的子类（如锁、线程、信号量）只能通过指针或引用传递，从源头上杜绝因资源意外拷贝导致的崩溃和泄漏。

#### 设计理念
在 C++ 中，很多代表系统资源的对象（如线程、锁、信号量、文件描述符）在逻辑上是不允许被拷贝的。拷贝这类对象会导致资源所有权模糊，进而引发双重释放（Double Free）或浅拷贝导致的数据竞争。

#### 设计要点
- **`= delete`**: 利用 C++11 的新特性明确禁用拷贝构造函数 and 赋值运算符。
- **编译期拦截**: 错误发生在编译阶段，而不是运行阶段，极大降低了调试成本。

#### 遇到的问题
##### Q: 为什么不直接在每个类里写 `delete`？
**A**: **约定优于重复**。通过继承 `Noncopyable`，开发者可以一眼看出该类是一个“资源管理类”而非“数据存储类”。这是一种语义上的契约，同时也让代码更加整洁，避免了大量的冗余代码。

##### Q: 为什么析构函数不使用 `virtual`?
**A**: 因为 `Noncopyable` 并不打算通过基类指针来销毁子类对象（即不会出现 `Noncopyable* p = new Mutex(); delete p;` 这种情况）。它仅仅是一个功能性的标记。不使用 `virtual` 可以避免产生虚函数表（vtable），保证子类在内存布局上没有任何额外的性能开销。

##### Q: 既然拷贝构造是 `= delete`，为什么默认构造要写 `= default`？
**A**: 这是为了防止“误伤”基础初始化能力。
- **编译器规则**: C++ 规定，如果你显式定义了任何构造函数（包括声明为 `= delete` 的拷贝构造），编译器就不会再自动生成默认构造函数。
- **`= default` 的作用**: 如果不写它，`Noncopyable` 就没有默认构造函数，导致子类（如 `Mutex`）在初始化时无法完成“筑基”过程而报错。
- **结论**: `= delete` 是为了主动切断特定能力（拷贝），而 `= default` 是为了在定义了其他构造函数的情况下，主动恢复最基础的初始化能力，确保子类能正常创建。

---

### 4. Singleton (单例模板)
#### 类作用
系统的"全局唯一管家"。提供通用的单例模式模板，支持返回裸指针和智能指针两种方式，确保全局只有一个实例。

#### 设计理念
单例模式是一种创建型模式，保证一个类只有一个实例，并提供全局访问点。在服务器框架中，单例常用于管理器类（如 FdManager、LoggerManager）。

#### 设计要点
- **`Singleton<T>`**: 返回单例裸指针 `T*`
- **`SingletonPtr<T>`**: 返回单例智能指针 `shared_ptr<T>`
- **模板参数 X**: 用于区分同一类型的不同单例实例（Tag）
- **模板参数 N**: 同一个 Tag 下可以创建多个实例索引
- **线程安全**: C++11 保证 `static` 局部变量的初始化是线程安全的

#### 遇到的问题
##### Q: 为什么在 `namespace sylar` 中还有一个匿名 `namespace`？
**A**: 这是一个巧妙的设计模式，用于**隐藏实现细节**和**防止符号冲突**。

1. **匿名命名空间的特性**：
   ```cpp
   namespace sylar {
       namespace {  // 匿名命名空间
           template <class T, class X, int N>
           T &GetInstanceX() {
               static T v;
               return v;
           }
       }
   }
   ```
   - 匿名命名空间内的内容具有**内部链接性** (internal linkage)
   - 相当于给每个函数都加上了 `static` 关键字
   - 这些函数只在当前编译单元（.cc 文件）内可见

2. **为什么要这样设计**？
   - **防止符号冲突**: 如果多个 .cc 文件 include 这个头文件，没有匿名命名空间就会产生**多重定义错误**。匿名命名空间确保每个编译单元都有自己的副本，互不干扰。
   - **隐藏实现细节**: 外部无法直接调用 `sylar::GetInstanceX<...>()`，这是**私有实现**，只能通过公共接口 `Singleton<T>::GetInstance()` 访问。
   - **灵活重构**: 这些辅助函数可以被修改或删除，而不影响用户代码。

3. **对比**：
   ```cpp
   // ❌ 错误：全局可见，多个 .cc include 会冲突
   namespace sylar {
       template <class T, class X, int N>
       T &GetInstanceX() { ... }
   }

   // ✅ 正确：内部可见，每个编译单元独立
   namespace sylar {
       namespace {
           template <class T, class X, int N>
           T &GetInstanceX() { ... }
       }
   }
   ```

**总结**: 匿名命名空间是一种**封装技巧**，将辅助函数隐藏起来，既保持了代码的组织性，又避免了链接冲突。

##### Q: 单例模式中 `static` 局部变量的线程安全性是如何保证的？
**A**: C++11 标准明确规定：编译器必须保证 `static` 局部变量的初始化是线程安全的。

- **C++11 之前**: 编译器通常通过全局锁或其他机制来保证，但不是标准要求
- **C++11 及之后**: 标准强制要求，编译器必须生成线程安全的初始化代码
- **实现机制**: 编译器通常会生成类似以下的伪代码：
  ```cpp
  void* getInstance() {
      static bool initialized = false;
      static T instance;

      // 编译器自动生成的线程安全检查
      if (!initialized) {
          lock_guard<mutex> lock(some_mutex);
          if (!initialized) {
              new (&instance) T();  // placement new
              initialized = true;
          }
      }
      return &instance;
  }
  ```

这种机制被称为**Magic Statics**（魔法静态变量），是 C++11 最受欢迎的特性之一。

---

### 5. 位域（Bit Field）优化
#### 类作用
精确控制类成员变量的内存占用，通过指定每个成员占用的位数，实现内存压缩。

#### 设计理念
对于只需要 0/1 状态的布尔标志，使用 1 bit 存储即可，无需分配完整的 bool（1 字节）。当多个布尔标志紧密排列时，可以显著节省内存。

#### 设计要点
- **语法**: `bool m_flag : 1;` 表示该成员只占 1 bit
- **内存对齐**: 编译器会将位域成员打包到尽可能少的存储单元中
- **适用场景**: 大量标志位（flags）、状态机状态、紧凑数据结构

#### 遇到的问题
##### Q: FdCtx 类中的五个 bool 为什么要使用位域？
**A**: 为了**内存优化**和**批量实例管理**。

**内存对比**：
```cpp
// ❌ 不用位域（每个 bool 占 1 字节 = 8 bits）
class FdCtx {
    bool m_isInit;       // 8 bits
    bool m_isSocket;     // 8 bits
    bool m_sysNonblock;  // 8 bits
    bool m_userNonblock; // 8 bits
    bool m_isClosed;     // 8 bits
    // 总计：40 bits = 5 字节
    // 加上内存对齐，可能占 8 字节
};

// ✅ 使用位域（每个 bool 占 1 bit）
class FdCtx {
    bool m_isInit : 1;       // 1 bit
    bool m_isSocket : 1;     // 1 bit
    bool m_sysNonblock : 1;  // 1 bit
    bool m_userNonblock : 1; // 1 bit
    bool m_isClosed : 1;     // 1 bit
    // 总计：5 bits（可以塞进 1 个字节里）
    // 加上其他成员，内存对齐后可能仍占 8 字节
};
```

**实际效果**：
```cpp
// 场景：系统中有 10 万个文件描述符
// 不用位域：每个 FdCtx 的标志部分占 5 字节
// 总内存：100,000 × 5 = 500 KB

// 使用位域：每个 FdCtx 的标志部分占 1 字节
// 总内存：100,000 × 1 = 100 KB
// 节省：400 KB！
```

##### Q: 位域的内存是如何分配的？
**A**: 编译器会按照**声明顺序**将位域成员打包到存储单元中。

**示例**：
```cpp
class Example {
    bool a : 1;  // 第 0 bit
    bool b : 1;  // 第 1 bit
    bool c : 1;  // 第 2 bit
    bool d : 1;  // 第 3 bit
    bool e : 1;  // 第 4 bit
    bool f : 1;  // 第 5 bit
    bool g : 1;  // 第 6 bit
    bool h : 1;  // 第 7 bit
    // 填满 1 个字节（8 bits）

    int x;        // 从新字节开始
};
```

**跨字节边界**：
```cpp
class Example {
    bool a : 7;  // 占 7 bits
    bool b : 5;  // 需要 5 bits，但当前字节只剩 1 bit
    // 编译器会将 b 放到下一个字节
};
```

##### Q: 位域有什么限制和注意事项？
**A**: 位域有一些重要的限制：

**1. 不能取地址**：
```cpp
class FdCtx {
    bool m_isInit : 1;
};

// ❌ 错误：不能取位域的地址
bool* p = &ctx.m_isInit;  // 编译错误！

// ✅ 正确：可以读取值
bool flag = ctx.m_isInit;
```

**2. 位域只能是整数类型**：
```cpp
// ✅ 正确
bool m_flag : 1;
int m_value : 8;     // 占 8 bits（0-255）
unsigned int m_x : 16;

// ❌ 错误：不能用浮点数、对象、引用
float m_f : 1;       // 编译错误
std::string m_s : 1; // 编译错误
```

**3. 跨平台注意事项**：
```cpp
// 不同编译器打包方式可能不同
// 不同字节序（大端/小端）会影响位顺序
// 在网络编程中要特别小心
```

##### Q: 什么时候应该使用位域？
**A**: 明确的权衡标准：

**适合使用位域的场景** ✅：
- **大量标志位**：如 FdCtx 有 5 个 bool，节省内存明显
- **紧凑数据结构**：网络协议、嵌入式系统、内存受限环境
- **状态机**：只需几个状态，不需要完整字节
- **数组/容器**：成千上万个实例，每个节省几字节就很可观

**不适合使用位域的场景** ❌：
- **少量标志位**：1-2 个 bool，位域优化不明显
- **需要取地址**：要传指针给其他函数
- **性能敏感**：位操作可能有微小性能开销（现代编译器通常能优化）
- **跨平台代码**：不同编译器行为可能不一致

**经验法则**：
- 如果有 **5 个以上的 bool 标志**，考虑位域
- 如果对象会被 **大量实例化**（如 FdCtx 管理所有 fd），考虑位域
- 如果只是 **少量临时对象**，不值得优化

##### Q: 为什么 FdCtx 的位域声明顺序很重要？
**A**: 为了**内存布局的可预测性**和**对齐优化**。

```cpp
class FdCtx {
    bool m_isInit : 1;       // 第 0 bit
    bool m_isSocket : 1;     // 第 1 bit
    bool m_sysNonblock : 1;  // 第 2 bit
    bool m_userNonblock : 1; // 第 3 bit
    bool m_isClosed : 1;     // 第 4 bit
    // 剩 3 bits 未使用（浪费）

    int m_fd;                // 从新对齐边界开始
    uint64_t m_recvTimeout;
    uint64_t m_sendTimeout;
};
```

**编译器优化**：
现代编译器会自动将对齐的成员（如 int、uint64_t）放在合适的边界上，位域的影响被最小化。

**总结**：位域是 C++ 提供的内存优化工具，在合适的场景下使用可以显著节省内存，但要权衡可读性、可维护性和性能。

---

## 并发模块 (Concurrency Module)

### 1. Semaphore (信号量)
#### 类作用
线程间的“交通信号灯”。它作为一个原子的资源计数器，负责在多线程环境下控制并发访问的数量，或者作为“生产-消费”模型中的唤醒机制（唤醒睡觉的线程去干活）。

#### 设计理念
信号量是一种“资源计数器”，用于多线程间的同步与资源控流。在协程调度器中，它作为线程的“唤醒闹钟”，确保 CPU 资源不被浪费在忙轮询上。

#### 遇到的问题
##### Q: 为什么派生类继承了 Noncopyable 还需要定义自己的析构函数？
**A**: 这是 **“禁止拷贝”** 与 **“资源清理”** 的职责分离。
- `Noncopyable` 的析构函数（基类）只负责完成销毁链条的闭环，不处理具体业务。
- `Semaphore` 的析构函数（派生类）必须亲手调用 `sem_destroy` 来释放 C 风格的系统资源 `sem_t`。
C++ 的自动清理仅限类成员对象，对于通过系统调用申请的内核资源，必须在析构函数中显式手动释放，否则会导致系统级资源泄漏。

##### Q: 派生类重写了析构函数，基类的析构函数还有效吗？
**A**: **永远有效**。C++ 的析构过程遵循 **“先子后父”** 的顺序（拆楼模型：先拆顶层阁楼，再拆地基）。
1. 执行子类 `~Semaphore()`，清理 `sem_t`。
2. 自动调用父类 `~Noncopyable()`。
即使基类析构函数是空的或者是虚函数，这个链式调用也绝不会中断。**虚析构函数**的作用不是为了“覆盖”父类逻辑，而是为了确保当使用父类指针删除子类对象时，销毁流程能从正确的子类位置开始。

##### Q: 信号量的工作原理是什么？Windows 有吗？
**A**: **借书模型**。
- **初始值**: 代表可用资源的数量（如 3 本书）。
- **P 操作 (wait)**: 资源 > 0 则减 1 拿走；资源 = 0 则线程挂起“睡觉”。
- **V 操作 (notify)**: 资源加 1 并“踢醒”一个正在睡觉的线程。
Windows 同样拥有信号量（`CreateSemaphore`），它是内核对象。与 Linux (POSIX) 相比，Windows 信号量功能更强（可跨进程），但开销略大。

#### 技巧
- **中断处理**: 在 Linux 下，执行 `sem_wait` 可能被系统信号中断返回 `EINTR`。实现时必须使用 `while` 循环包裹，确保线程只有在真正获得资源或发生致命错误时才返回。

---

### 2. ScopedLockImpl (局部锁模板)
#### 类作用
系统的“自动看门人”。它利用 RAII 机制，将锁的生命周期与局部变量的作用域绑定。确保在任何情况下（如函数执行完毕、提前 return 或抛出异常），锁都能被正确释放，彻底解决死锁隐患。

#### 设计理念
让开发者专注于业务逻辑，而无需操心加锁与解锁的配对。

#### 遇到的问题
##### Q: 为什么成员变量 m_mutex 必须是引用类型 T&？
**A**: 锁的本质是“唯一性”与“认同感”。
1. **禁止拷贝**: 锁对象通常继承自 Noncopyable。如果使用传值，编译器会尝试拷贝锁，导致编译失败。
2. **操作原件**: 引用确保了 ScopedLock 手里拿到的“钥匙”就是调用者传进来的那把原始钥匙。任何加锁/解锁操作都直接作用于原对象。
3. **安全性**: 引用强制要求在构造时必须绑定到一个已存在的锁对象，且不能为空，这比使用指针更加健壮。

---

### 3. 同步策略对比 (Lock vs RdLock vs WrLock)
#### 核心差异
- **lock() (Mutex)**: 独占互斥。无论读写，一次仅限一人。适用于写操作频繁或数据竞争剧烈的场景。
- **rdlock() (Read Lock)**: 共享读锁。允许多读，禁止写。适用于“多读少写”的场景，能显著提升并发性能。
- **wrlock() (Write Lock)**: 独占写锁。禁止一切读写。当有人要写时，它会等待所有读锁释放，并拦截后续的所有读请求，确保一致性。

#### 抉择建议
1. 如果数据频繁更新，建议使用普通的 Mutex::lock()，因为读写锁内部维护读计数器的开销有时会抵消掉并发带来的收益。
2. 如果数据大部分时间是只读的（如配置信息、路由表），务必使用 RWMutex 的读写分离锁。

---

### 4. 局部锁与 Mutex 的协同逻辑 (RAII 深度解析)
#### 模块作用
通过“外壳与引擎”的分工，实现同步逻辑所在的自动化与标准化。

#### 核心原理
RAII 局部锁（如 ScopedLockImpl）与具体的锁实现（如 Mutex）之间是一种耦合协作关系。

#### 遇到的问题
##### Q: sylar::Mutex::Lock lock(m_mutex); 的实际执行过程是怎样的？
**A**: 这是一次完美的模板替换与 RAII 生命周期结合的演示：
1. **类型确定**: 编译器根据 typedef 将 Mutex::Lock 映射为 ScopedLockImpl<Mutex>。
2. **构造加锁**: 局部变量 lock 在栈上创建，构造函数立即调用 m_mutex.lock()。由于模板替换，这实际上精准执行了 Mutex 类中封装的底层系统锁操作。
3. **作用域保护**: 只要 lock 变量在生命周期内，锁就一直被持有。
4. **析构释放**: 当 lock 离开作用域（正常退出或异常）被销毁时，析构函数自动执行 m_mutex.unlock()，将锁归还系统。

##### Q: ScopedLockImpl 里的 m_mutex.lock() 到底调的是谁？
**A**: 这是由“接口契约”决定的。在编译阶段，编译器会根据传入的模板参数 T 进行静态替换。
- 如果 T 是 Mutex，调用的就是 Mutex::lock()。
- 如果 T 是 NullMutex，调用的就是空函数。
这种方式实现了编译期多态，既消除了重复代码，又实现了零开销的性能优化。

##### Q: Mutex 的构造函数什么时候被调用？它与 ScopedLock 有何区别？
**A**: 这是“资源初始化”与“资源使用”的关系。
- **Mutex 构造 (初始化)**: 在 Mutex 对象定义时执行（如作为成员变量随类初始化、或作为全局变量在 main 前初始化）。一辈子只执行 **1 次**，负责向系统申请锁资源（`pthread_mutex_init`）。
- **ScopedLock 构造 (使用)**: 在每次需要保护代码块时临时创建。在程序运行期间可能执行 **千万次**，负责调用已初始化好的 Mutex 的 `lock` 接口。
- **完整生命周期**: 
  1. `Mutex()` 构造（安装房门并配好锁）。
  2. `ScopedLock()` 构造 -> 调用 `Mutex::lock()`（伸手去拧开锁）。
  3. `ScopedLock()` 析构 -> 调用 `Mutex::unlock()`（随手把锁关上）。
  4. `~Mutex()` 析构（拆除房门，资源归还操作系统）。

#### 总结
- **ScopedLockImpl (管理者)**: 负责管控“加锁与解锁的时机”，属于通用逻辑。
- **Mutex (执行者)**: 负责提供“加锁与解锁的能力”，属于具体实现。
两者结合实现了：将复杂性留在底层（Mutex），将安全性留给中间层（RAII），将简洁留给最终用户。

---

### 5. NullMutex (空锁)
#### 类作用
它是为“性能优化”和“代码复用”而生的模板策略类。它提供与 Mutex 完全一致的接口（lock/unlock），但内部实现为空。

#### 遇到的问题
##### Q: NullMutex 是干什么用的？为什么需要一个“假锁”？
**A**: 它是为“性能优化”和“代码复用”而生的模板策略类。
- **设计场景**: 在模板编程中，当一个底层组件（如配置系统或日志缓冲区）需要支持自定义锁时，开发者可以通过传入 NullMutex 来关闭加锁逻辑。
- **核心优势**: 
  1. **代码复用**: 同一套业务逻辑，只需通过切换模板参数，即可完美适配多线程安全场景与单线程极致性能场景。
  2. **零开销抽象**: 编译器会通过内联优化直接剔除 NullMutex 的空函数调用，确保在关闭锁时没有任何性能损耗。
- **比喻**: 它就像是程序架构里的“安慰剂”，保持了接口的完整性，但在执行层面完全消除了开销。

---

### 6. RWMutex (读写锁)
#### 类作用
高并发场景下的“读性能加速器”。它通过区分读操作和写操作，允许多个线程同时进行读访问，仅在写操作时进行独占锁定，极大提升了以读为主的数据结构的吞吐量。

#### 核心机制：pthread_rwlock_t
- **共享与独占**: 
  - 多个 pthread_rwlock_rdlock 可以同时成功，底层通过引用计数管理读状态。
  - pthread_rwlock_wrlock 是排他的，只要有任何线程在读或写，写加锁都会阻塞。
- **饥饿预防 (Starvation)**: 
  - 现代 Linux 实现通常具有写优先权。如果写锁正在排队，后续的读锁请求会被阻塞，防止写操作被无限期的读请求“饿死”。
- **单一解锁接口**: 
  - pthread_rwlock_unlock 能够自动识别当前线程持有的是读锁还是写锁并执行相应的释放动作。

#### 抉择建议
- **适用场景**: 配置项管理、日志器列表等“多读少写”的数据结构。
- **性能权衡**: 读写锁由于要维护读计数器的原子操作，其本身的加解锁开销比普通 Mutex 略大。只有在临界区内停留时间较长，且并发读请求远多于写请求时，收益才明显。

---

### 7. Spinlock & CASLock (轻量级自旋锁)
#### 类作用
追求极致性能的同步原语。它们通过“原地自旋”代替“挂起睡眠”，消除了线程上下文切换的开销，适用于临界区极短的并发场景。

#### 核心机制
- **自旋锁 (Spinlock)**: 对 `pthread_spinlock_t` 的封装。
  - **特点**: 系统级 API，由操作系统和底层库决定自旋策略。
  - **使用注意**: `pthread_spin_lock` 内部已包含死循环逻辑，调用者无需在外部额外加循环。
- **原子锁 (CASLock)**: 利用 C++11 `std::atomic_flag` 实现。
  - **特点**: 纯用户态实现，绝对无锁（lock-free）。
  - **逻辑关键**: 使用 `test_and_set` (原子级“检查并设置”)。若返回 `false`（表示原状态为开），则成功夺锁并自动设为关；若返回 `true`（表示已关），则继续 `while` 循环。
  - **优势**: 允许通过 `memory_order_acquire/release` 精准控制内存屏障，跨平台一致性更高。

#### 遇到的问题
##### Q: 既然代码结构和 Mutex 没区别，为什么
U 占用。

##### Q: CASLock 看起来就是手写了 Spinlock 的循环，为什么要两个都写？
**A**: 这是“官方封装”与“手工 DIY”的权衡。
- `Spinlock` 是稳妥的官方黑盒。
- `CASLock` 是透明的现代白盒，能更精细地控制内存顺序（Memory Order），在高性能调优中更具优势。

##### Q: 什么是 std::atomic_flag？它是如何实现锁的？
**A**: 它是 C++ 标准中定义的原子布尔标志位，具有以下特殊地位：
1. **绝对无锁**: 它是唯一保证在所有平台上都通过单一 CPU 指令实现的 lock-free 类型（不像 `std::atomic<bool>` 可能在某些平台上用锁模拟）。
2. **核心动作 (test_and_set)**: 这是一个原子性的“检查并设置”动作。它会尝试把标志设为 true，并返回拧开关之前的旧状态。
3. **实现锁的逻辑**: 
   - `while(flag.test_and_set())`: 如果旧状态是 false（开门），则设置成功并跳出循环进入临界区；如果旧状态是 true（关门），则继续自旋。
   - **语义解释**: “本以为门是开着的我就去锁它，如果它告诉我确实是开着的，那我就抢占成功了；否则我就死等。”

---

### 8. Thread (线程类)
#### 类作用
并发模块的“大管家”。封装了 POSIX 线程 (pthread)，通过 RAII 管理线程的生命周期，并负责初始化线程局部存储 (TLS) 环境，为上层协程模块提供基础设施。

#### 设计理念
利用 `thread_local` 实现线程上下文的自我感知，通过静态方法提供全局访问点。

#### 遇到的问题
##### Q: 为什么 `t_thread` 变量要定义为 `static thread_local`？
**A**: 这是为了同时控制 **生命周期** 和 **可见性**。
- **`thread_local`**: 确保每个线程都有一份独立的变量副本（TLS），线程 A 修改不会影响线程 B。
- **`static`**: 限制该变量的可见性仅在当前编译单元（.cc 文件）内部。这防止了全局命名空间污染，强制外部只能通过 `Thread::GetThis()` 接口访问，增强了封装性。

##### Q: 为什么需要两份线程名称（m_name 和 t_thread_name）？它们有什么区别？
**A**: 这是为了在 **“对象管理”** 与 **“执行流效率”** 之间取得平衡。实质上，线程名称在系统中是“三方同步”的：
1. **m_name (成员变量 - 给别人看的)**: 存在于 Thread 对象实例中（堆内存）。让外部持有该线程指针的人（如调度器）能随时查询该线程的名字。
2. **t_thread_name (TLS 变量 - 给自己看的)**: 存在于每个线程独立的 TLS 区域。用于极速读取，日志系统打印日志时直接从 TLS 读取字符串，效率远高于通过指针跳转访问对象成员。且能兼容非 sylar 管理的线程（如 main 线程）。
3. **pthread_setname_np (内核记录 - 给系统看的)**: 写入 Linux 内核任务元数据中。让系统工具（如 top, ps, gdb）能直接显示线程名称，极大方便了监控和调试。
**总结**: 我们在 Thread::SetName 中同步修改这三处，确保无论从对象、执行流还是内核视角观察，线程名称都是一致且最新的。

##### Q: 为什么在 Thread::run 中要使用 swap 转移业务逻辑？
**A**: 这是一处极其严谨的内存与逻辑优化，被称为“责任转移”：
1. **减少引用计数 (内存优化)**: 业务逻辑 `m_cb` 可能持有智能指针。通过 `swap` 转移到局部变量 `cb`，保证业务执行完后 `cb` 立即析构，从而释放捕获的资源，防止对象生命周期被意外拉长。
2. **语义安全 (逻辑优化)**: 确保 `m_cb` 里的业务逻辑只被执行一次。`swap` 后 `thread->m_cb` 变为空，逻辑上更清晰且安全。
3. **分离职责**: 使 Thread 对象的生命周期与业务逻辑的执行过程彻底解耦。

##### Q: 既然静态函数不能访问非静态成员，为什么还要把 GetThis() 等设为静态？
**A**: 这是为了实现“全局无感访问”。如果设为普通成员函数，调用者必须持有具体的 Thread 对象指针才能调用；而设为静态并配合 TLS 变量，开发者可以在代码的任何角落（哪怕是在一个完全不认识 Thread 类的底层函数或全局逻辑中）直接获取当前线程的身份信息。这种设计解耦了业务代码与线程管理对象的传递，极大地方便了日志等基础模块的使用。

##### Q: 构造函数里直接执行 m_semaphore.wait() 安全吗？为什么要阻塞住？
**A**: 它是绝对安全且必要的。
1. **安全性保证**: C++ 保证类成员变量的初始化发生在构造函数体执行之前。由于 m_semaphore 是成员变量，进入构造函数时它已初始化完毕。
2. **解决竞态条件**: pthread_create 是异步的。如果不阻塞，主线程构造函数可能在子线程还没跑起来时就返回了。此时主线程若立即调用 getId()，子线程可能还没来得及执行 GetThreadId() 赋值，导致主线程拿到初始值 -1。
3. **环境契约**: 通过信号量同步，我们强制主线程等待，直到子线程在 run 入口函数里彻底初始化完 TLS 环境和系统 ID。这保证了“只要 Thread 对象被创建成功，它的所有环境信息都是立即可用的真实状态”。

##### Q: 线程入口函数是什么意思？为什么非得是静态的？
**A**: 入口函数是子线程生命开始的“起跑线”。
1. **定义**: 当调用 `pthread_create`时，操作系统会分配资源并将执行流跳转到指定的函数。在我们的类中，这个数就是 `Thread::run`。
2. **为什么必须是 static**:
- **C 风格约束**: `pthread_create` 是一个 C语言接口，它要求传入的函数指针格式必须是 `void* (*)(void*)`。
- **屏蔽 this**: C++ 的普通成员函数隐含了一个 `this`指针作为第一个参数，这与 C 接口的要求不符。
- **解决方案**: 静态成员函数不属于任何具体对象，没有隐含的 `this`指针，其内存布局与全局函数一致，因此能完美匹配 C 接口。
3. **在框架中的角色**: `run` 函数充当了“装修工”的角色。它利用传入的`arg` (即 `this` 指针)回过头来访问非静态成员，在执行用户真正的业务代码（`m_cb`）之前，先把TLS 环境初始化、线程命名、ID 登记等“脏活累活”干完。

---

## 协程模块 (Fiber Module)

### 1. Fiber (协程类)
#### 类作用
系统的“微型执行单元”。它通过手工操作 CPU 上下文（ucontext_t），实现在单个线程内进行多任务切换。

#### 设计理念
采用 **“非对称协程模型”**：子协程必须与主协程成对切换 (Resume/Yield)。

#### 2. 协程底层支撑：ucontext 族函数详解
在 Linux 下，我们使用 `<ucontext.h>` 提供的 API 来实现用户态上下文切换。

##### (1) ucontext_t 结构体
这是上下文的“档案袋”，核心成员：
- `uc_link`: 后继上下文指针。
- `uc_stack`: 栈内存信息（`ss_sp` 指针，`ss_size` 大小）。
- `uc_mcontext`: 机器上下文，保存 CPU 寄存器状态。

##### 如何使用这些成员？
1. **栈分配**: 必须为子协程的 `uc_stack.ss_sp` 分配独立内存（如 1MB）。若不分配，子协程会污染主线程的栈，导致程序瞬间崩溃。
2. **跳转管理**: 将 `uc_link` 设为 `nullptr`。这意味着协程结束后不会自动跳转，强制我们在 `MainFunc` 中手动处理切回主协程的逻辑，从而实现对协程生命周期的精准管控。
3. **寄存器“底片”**: 开发者不直接操纵 `uc_mcontext`。我们通过 `getcontext` 抓取一份当前的寄存器快照作为模板，再由 `makecontext` 修改其中的入口指令地址（PC）和栈指针（SP）。

##### (2) getcontext(ucontext_t *ucp)
- **作用**: 抓取当前 CPU 上下文快照存入 `ucp`。
- **返回值**: 
  - 成功：返回 0。
  - 失败：返回 -1，并设置 errno。
- **在项目中**: 用于初始化主协程环境或作为子协程环境的模板。
- **代码示例**:
  ```cpp
  ucontext_t ctx;
  getcontext(&ctx); // 此时 ctx 记录了执行到这一行时的所有寄存器状态
  ```

##### (3) makecontext(ucontext_t *ucp, void (*func)(), int argc, ...)
- **作用**: 修改上下文。指定该上下文激活后去跑哪个函数。
- **前提**: 必须先调 `getcontext` 并手动配置 `uc_stack` 和 `uc_link`。
- **在项目中**: “捏造”子协程的起跑线，指定执行 `Fiber::MainFunc`。
- **代码示例**:
  ```cpp
  ucontext_t ctx;
  getcontext(&ctx);
  ctx.uc_stack.ss_sp = malloc(1024*1024);
  ctx.uc_stack.ss_size = 1024*1024;
  ctx.uc_link = nullptr;
  makecontext(&ctx, &Fiber::MainFunc, 0); // 修改入口指令地址
  ```

##### (4) swapcontext(ucontext_t *oucp, const ucontext_t *ucp)
- **作用**: **核心切换引擎**。保存当前上下文到 `oucp`，并立即恢复（跳转）到 `ucp`。
- **返回值**: 
  - 成功：该函数不返回（因为执行流已经跳走了）。只有当 `oucp` 以后被重新激活时，它才看起来像是从 `swapcontext` 返回了，且此时返回 0。
  - 失败：返回 -1，并设置 errno。
- **在项目中**: 实现 `resume` 和 `yield` 的“跷跷板”式切换。
- **代码示例**:
  ```cpp
  // 从当前协程切换到目标协程 ucp，并将当前现场保存到 oucp
  swapcontext(&oucp, &ucp); 
  ```

#### 遇到的问题
##### Q: 为什么全局计数器 s_fiber_id 和 s_fiber_count 要写在 .cc 而不是 .h 中？
**A**: 这是基于 **“符号可见性”** 与 **“工程安全性”** 的考虑：
1. **防止副本**: 在 `.h` 定义 `static` 变量会导致每个包含它的单元都生成一份独立副本，使全局计数失效。
2. **物理隔离**: 写在 `.cc` 中并标记为 `static` 具有内部链接属性，外部代码无法修改这些“管理账本”，保证了数据安全。
3. **编译优化**: 隐藏实现细节，修改这些变量时无需触发全量重编译。

##### Q: 为什么 s_fiber_count 统计的是整个进程的协程数，而不是当前线程的？
**A**: 这涉及到宏观资源监控与协程“流动性”的设计：
1. **宏观监控**: 协程栈是昂贵的资源（默认 1MB/个）。全局计数能让开发者一眼看出整个进程的内存负载，而非碎片化的线程信息。
2. **支持任务跨线程**: 协程可能被调度器从 A 线程“偷”到 B 线程运行并析构。全局原子计数器能完美处理这种“出生地”与“坟墓”不一致的情况，确保统计永不偏离。
3. **实现一致性**: 与其定义位置（.cc 文件中的静态变量）相匹配，体现了“跨线程共享，全进程唯一”的管理意志。

##### Q: MainFunc 函数的设计逻辑是怎样的？为什么要设计得如此复杂？
**A**: `MainFunc` 是协程生命的“摇篮”与“终点站”，其设计核心在于实现 **“异常绝缘”** 与 **“破解自引用导致的内存泄漏”**。

1. **异常绝缘 (Exception Barrier)**:
   - **设计**: 必须使用 `try-catch` 全面包裹业务代码 `m_cb`。
   - **原因**: 协程是在用户态模拟的执行流。如果协程内部抛出异常而未被捕获，这个异常在向上冒泡时无法被操作系统接管（因为没有标准的内核栈帧链），最终会导致整个主线程、甚至整个进程直接崩溃。通过捕获异常并将其转为 `EXCEPT` 状态，我们为系统构建了一道防火墙。

2. **解决“自引用”导致的内存泄漏 (核心设计)**:
   - **代码动作**: 采用“三步跳”收尾：`raw_ptr = cur.get(); cur.reset(); raw_ptr->yield();`
   - **陷阱描述**: `cur` 是一个智能指针（`shared_ptr`），它存在于子协程的 **“私有栈”** 上。
   - **死锁逻辑**: 
     - 当子协程执行完并准备切回主协程时，如果直接调用 `cur->yield()`，由于切换后子协程的栈帧会被保留（为了存上下文），栈上的变量 `cur` 就依然有效。
     - 此时，`cur` 依然攥着协程对象的一个引用计数。
     - 当控制权回到主协程后，即便主协程持有的 `shared_ptr` 析构了，它会发现引用计数仍不为 0（因为子协程自己的栈里还藏着一个 `cur` 盯着自己）。
     - 这导致了：**主协程想销毁子协程，但子协程手里攥着自己的命，导致谁也释放不了。**
   - **破局方案**: 
     - 1. 先用不增加计数的原始指针 `raw_ptr` 记住地址。
     - 2. 手动执行 `cur.reset()`。这一步彻底抹除了子协程栈上对自身的引用。
     - 3. 利用原始指针完成最后一跳。这样当回到主协程后，该对象的引用计数能精准归零，实现内存的即时回收。

##### Q: swapcontext 只是切换了上下文，为什么子协程就能立刻“识别”并开始执行？
**A**: 这是一个关键误区：子协程不需要“识别”切换，因为在 `swapcontext` 完成的那一刻，CPU 的“大脑”已经被强行改装成了子协程的样子。

1. **指令指针覆盖 (RIP/PC) —— 改变“目的地”**: 
   - CPU 内部最核心的寄存器是程序计数器（RIP）。它就像 CPU 的 GPS，永远指向下一厘米代码的地址。
   - `makecontext` 预先在子协程的 `ucontext_t` “档案袋”里的 RIP 位置写下了 `MainFunc` 的入口地址。
   - `swapcontext` 执行时，CPU 会把这个地址直接加载到自己的物理寄存器里。
   - **结果**: CPU 根本不知道自己换了环境，它只是机械地去读 RIP 指向的下一条指令，而这条指令已经瞬间变成了子协程的第一行代码。

2. **栈指针迁移 (RSP/SP) —— 改变“办公桌”**:
   - 切换指令同时修改了栈指针寄存器，使其指向子协程私有的 1MB 内存。
   - **结果**: CPU 发现不仅代码变了，连存放局部变量的“工作台”也瞬间变成了一张全新的、空净的桌子。

**形象比喻：失忆的旅行者**
- **CPU** 就像一个 **“失忆的旅行者”**：他每走一步，都要低头看一眼手里的 GPS（RIP 寄存器）。
- **协程切换** 就像是一次 **“空间平移”**：
  - 当主协程调用 `swapcontext` 时，趁旅行者（CPU）低头看路的一瞬间，我们强行换掉了他手里的 GPS，并把他平移到了另一个城市的街道上。
  - 旅行者抬头时，根本不记得刚才在干什么，他只会低头看一眼新 GPS 上的指令。
  - GPS 说“往前走”（即 `MainFunc` 的入口），他便毫不怀疑地迈出了脚步。
- **结论**: 切换不是逻辑上的“通知”，而是物理层面的“夺舍”。通过直接改写 CPU 的寄存器硬件状态，我们让同一个线程在不同的上下文之间无感穿梭。

##### Q: reset() 函数的设计思路是什么？它体现了什么样的优化思想？
**A**: `reset()` 函数的设计是 **“对象池/池化 (Pooling)”** 思想在协程上的极致体现。

1. **资源成本考量**:
   - 子协程最昂贵的资源是那 1MB 的 **私有栈内存**。
   - 频繁地 `malloc` 和 `free` 大块内存会导致：
     - **CPU 损耗**: 内存分配器的管理开销。
     - **内存碎片**: 系统可用内存变得支离破碎。
     - **Cache 失效**: 新分配的内存通常是“冷”的，不利于 CPU 缓存。

2. **池化思想类比 (协程复用 vs 线程池)**:
   - **线程池**: 预先创建好内核线程，不销毁，通过 `while` 循环不断换任务跑。
   - **协程复用 (`reset`)**: 当一个协程的任务执行完（`TERM` 状态），我们不销毁该对象，而是通过 `reset()` 手动“格式化”其上下文，并绑定一个新任务函数。
   - **本质**: 两者都在追求 **“长效持有昂贵资源，动态切换廉价逻辑”**。

3. **reset 的核心逻辑**:
   - 检查该协程是否真的执行完了（必须是 `TERM` 或 `EXCEPT` 状态）。
   - 保留原本申请好的内存块（栈空间）。
   - 重新通过 `getcontext` 和 `makecontext` 在原内存上“重绘”执行环境。

**结论**: `reset` 让同一块栈内存能像接力赛一样，接完一个任务马上跑下一个，极大地提升了系统的吞吐量并降低了内存波动。

##### Q: 为什么子协程在构造函数里设置好了执行函数，却不会立即执行？
**A**: 这是协程与线程在调度权上的本质区别，体现了“用户态调度”的精髓：

1. **调度权的归属**: 
   - **线程 (`pthread_create`)**: 一旦创建，调度权即交给操作系统内核。内核会根据算法尽快安排其运行，程序员无法控制其启动的确切瞬间。
   - **协程 (`new Fiber`)**: 创建时仅仅是在用户态内存中开辟了空间并准备好了上下文快照。调度权完全掌握在程序员手中。

2. **“传送门”机制**: 
   - 构造函数只是“装修好了房间”（分配了栈）并“调好了 GPS 坐标”（预设了 RIP 寄存器指向 `MainFunc`）。
   - 此时，CPU 还在执行主协程的代码。由于没有内核介入，CPU 永远不会自动发现内存里躺着一个新协程。
   - **`resume()`** 是唯一的开关：只有执行了它内部的 `swapcontext`，CPU 才会物理性地切换寄存器，进而“发现”子协程的存在并开始执行。

3. **设计的优势**: 
   - **精准控制**: 允许先批量创建协程，再根据业务优先级决定启动顺序。
   - **确定性**: 执行流的切换点在代码中是完全显式的（就在 `resume()` 这一行），彻底消除了由于启动时机不确定导致的竞态。

**总结**: `new Fiber` 是“装修客房”，`resume()` 是“拎包入住”。如果不打开传送门，业务逻辑永远不会被动执行。

##### Q: 协程的“挂起 (HOLD)”状态是什么意思？它与“就绪 (READY)”有什么区别？
**A**: “挂起”是协程生命周期中一个关键的状态，可以通过“电影暂停键”的比喻来理解：

1. **形象理解 (电影比喻)**:
   - **运行 (EXEC)**: 电影正在播放，剧情往前推进。
   - **挂起 (HOLD)**: 你按下了“暂停键”。画面停在这一帧，播放进度（寄存器上下文）被记录在案。电影对象依然存在，它只是在后台静静等待被重新唤醒。
   - **恢复 (RESUME)**: 按下播放键，剧情从刚才停下的那一秒开始完美衔接。

2. **逻辑本质**: 
   - 执行 `YieldToHold()` 时，协程会通过 `swapcontext` 保存当前 CPU 现场并切回主协程。
   - 状态标记为 `HOLD` 意味着：该任务由于某种原因（通常是 IO 阻塞或等待定时器）无法继续执行，必须暂时从调度队列中移除。

3. **HOLD vs READY 的核心区别**:
   - **READY (就绪)**: 协程“还能跑”，只是主动把机会让给别人。调度器在下一轮循环中可以直接再次运行它。
   - **HOLD (挂起)**: 协程“暂时不能跑”。它必须等待一个外部事件（如网络数据到达）的触发。只有当外部事件发生并将其状态改回 `READY` 后，调度器才会再次理会它。

**结论**: “挂起”是实现高性能 IO 管理的基础：让 CPU 在等待数据的间隙去处理其他协程，实现了“逻辑上的同步，执行上的异步”。

##### Q: 协程如何实现“执行到一半让出 CPU，之后又能无感恢复”？（底层上下文切换原理）
**A**: 这不是魔法，而是通过 **“执行现场的物理封存与还原”** 实现的。

1. **什么是“执行现场”？**:
   - **寄存器组 (CPU Registers)**: 
     - **RIP (Instruction Pointer)**: 下一条指令的地址（决定了代码跑到了哪一行）。
     - **RSP (Stack Pointer)**: 当前栈顶位置（决定了局部变量存放在哪）。
     - **其他通用寄存器**: 保存了中间计算结果。
   - **栈内存 (Stack Memory)**: 存放了函数调用链和局部变量数据。只要 RSP 恢复，这些变量就“原地复活”。

2. **核心机制：swapcontext (存档/读档器)**:
   - 在 Sylar 的有栈协程设计中，每个 `Fiber` 对象都持有 `ucontext_t m_ctx` 档案袋和独立的 `m_stack` 栈空间。
   - **让出过程 (Yield/存档)**: 调用 `swapcontext(&子ctx, &主ctx)`。CPU 物理性地将当前的 RIP（指向 Yield 下一行）、RSP 拍照存入“子档案袋”，随即加载“主档案袋”的数据。
   - **恢复过程 (Resume/读档)**: 再次调用 `swapcontext(&主ctx, &子ctx)`。CPU 像读档一样，把子协程档案袋里的 RIP、RSP 写回硬件寄存器。

**形象比喻：游戏存档**:
- **Yield (存档)**: 玩到一半想吃饭，把当前关卡（RIP）、血量和背包（RSP/栈内存）存入小本本（`m_ctx`），然后加载“系统菜单”（调度器）去处理杂事。
- **Resume (读档)**: 拿出小本本，把关卡和血量写回屏幕。你一睁眼，发现自己正站在上次存档的地方，连怪物的血量都没变。

**总结**: 上下文切换的本质是 CPU 物理寄存器状态在不同“内存档案袋”之间的覆盖。由于不涉及内核态转换，这种“存档/读档”极快，是单机支撑百万并发的基石。

##### Q: 为了配合调度器，Fiber 类进行了哪些接口增强？为什么要这么做？
**A**: 在引入 N:M 调度模型（特别是 `use_caller` 模式）后，原有的单一切换路径已不足以支撑复杂的调度逻辑。我们进行了以下核心增强：

1. **状态管理接口 `setState()`**:
   - **作用**: 允许调度器合法地修改协程状态（如从 `EXEC` 改为 `HOLD`）。
   - **设计**: 采用公有接口而非友元类，保持了良好的封装性。

2. **多路径切换接口 `call()` 与 `back()`**:
   - **背景**: 在 `use_caller` 线程中，存在三种角色：主函数执行流、调度循环执行流、业务任务执行流。
   - **`call()`**: 专门用于“主函数执行流”主动切入“调度循环执行流”。它操作的是 `t_thread_fiber`（原始根协程）与 `m_rootFiber`（调度协程）之间的切换。
   - **`back()`**: 对应地，用于从调度循环切回主函数现场。

3. **逻辑增强版 `resume()` 与 `yield()`**:
   - **核心变化**: 增加了对 `m_runInScheduler` 标志位的识别。
   - **逻辑**: 
     - 如果该协程参与调度（`true`），`yield` 时会精准地跳回 **“当前线程的调度协程”**（即 `Scheduler::run` 所在的位置）。
     - 如果不参与调度（`false`），则跳回传统的 **“线程主协程”**。
   - **意义**: 这解决了“调度中断”问题。确保业务协程挂起后，CPU 是回到调度循环去领下一个活，而不是直接跳回 `main` 函数导致整个调度器停止转动。

**总结**: 
- **普通 `resume/yield`**: 解决“调度循环 <-> 业务任务”的横跳。
- **特殊 `call/back`**: 解决“主函数 <-> 调度循环”的纵跳，给use_caller 线程（主线程用的）。
这两套接口的配合，构成了多线程、多协程环境下严密的执行流闭环。

---

## 调度模块 (调度器模块)

### 1. Scheduler (协程调度器)
#### 类作用
系统的“总指挥部”。它内部管理着一个线程池，负责将大量的任务（函数或协程）高效地分发到各个线程上运行。它实现了“多对多”的调度模型（M:N），是支撑单机高并发的核心引擎。

#### 设计理念
实现“不让 CPU 闲着”的极致压榨。通过协程的主动让出（Yield）和调度器的自动切入（Resume），将原本在 IO 等待中浪费的时间碎片利用起来。

#### 遇到的问题
##### Q: 协程调度器与传统的线程池有什么区别？
**A**: 这是高性能服务器开发的核心分水岭，主要体现在以下四个维度：

1. **执行粒度的不同**:
   - **线程池**: 最小单位是“函数任务”。线程领到活后就开始闷头跑，不跑完不放手。
   - **调度器**: 最小单位是“执行上下文（协程）”。线程领到协程跑，若协程因等待 IO 挂起了，线程立即将其放下，转身去领下一个任务。

2. **阻塞表现的不同 (核心差异)**:
   - **线程池**: 如果任务在调同步 read()，该线程就被物理卡死了（进入内核睡眠）。
   - **调度器**: 任务在协程里通过 Yield 让出 CPU。线程本身不睡眠，它只是退出了当前协程，回到调度循环继续干别的活。

3. **任务形态的不同**:
   - **线程池**: 任务是一次性的，执行完即销毁。
   - **调度器**: 任务是“活”的。它支持暂停（Hold）和恢复（Resume），能够实现任务的“断点续传”。

4. **形象比喻 (厨师做饭)**:
   - **线程池模式**: 一个厨师领了一道菜。他站在锅边等水开，水不开他就不干别的活。你要同时烧 4 锅水，就得雇 4 个厨师。
   - **调度器模式**: 一个厨师领了 4 道菜。他先把火打开，趁水没开的空档，立刻去切菜、配料。一旦水开了，他再跳回锅边处理。
   - **结果**: 调度器模式下，一个厨师干了 4 个人的活，且从未空转发呆。

**总结**: 传统线程池是搬运工队，而协程调度器是一个具备“断点重连”能力的精细化资源管理中心。

##### Q: 什么是“当前线程的调度协程”？它有什么职责？
**A**: 调度协程（`t_scheduler_fiber`）是当前线程的“总管”或“指挥中心”。它不直接运行业务逻辑，只负责任务的“选拔与分发”。

1. **核心身份**: 它是专门运行 `Scheduler::run()` 调度主循环的那个协程。
2. **核心职责 (中转站)**:
   - **选活**: 不断从任务队列中挑选处于 READY 状态的协程或函数。
   - **切入 (Resume)**: 将 CPU 控制权移交给业务协程。
   - **接管 (Yield回)**: 当业务协程主动让出（Yield）或结束（TERM）时，控制权会物理性地跳回调度协程，使其能继续分发下一个任务。
3. **设计精髓**: 通过将调度逻辑“协程化”，我们将复杂的任务切换统一为了用户态下的协程间成对跳转，实现了高效的任务编排。

##### Q: “调度协程”是不是每个线程的“主协程”？
**A**: **不一定**。这是 Sylar N:M 调度模型中最关键的身份区分，需分场景讨论：

1. **普通工作线程 (线程池创建的线程)**:
   - **结论**: **是同一个**。
   - **逻辑**: 这种线程自诞生起的第一条指令就是跑调度器。因此，代表线程原始起点的“主协程”（`t_thread_fiber`）与负责分发的“调度协程”（`t_scheduler_fiber`）指向的是同一个上下文。

2. **use_caller 线程 (调用 start() 的原始线程，如主线程)**:
   - **结论**: **不是同一个，两者是分离的**。
   - **逻辑**: 
     - **主协程**: 依然代表你原本的 `main` 函数执行流（这是线程的“根”）。
     - **调度协程**: 是我们为主线程额外 `new` 出来的一个独立协程 `m_rootFiber`。
   - **中转逻辑**: 在这种线程中，业务协程 Yield 之后是跳回到 `m_rootFiber`（调度中心），而不是直接跳回 `main` 函数。只有当调度结束，主线程才会从调度协程切回主协程（`main`）。

**口诀记忆**: 普通工作线程是“司机就是车主”；use_caller 线程是“车主在后座办公，专门雇了个司机（调度协程）来开车”。

##### Q: 在 use_caller 模式下，为什么主线程需要额外 new 一个调度协程（m_rootFiber）？
**A**: 这是为了在主线程中实现 **“执行流的物理隔离与逻辑中转”**。

1. **解决“根现场”冲突**:
   - 每个线程都有一个原始的执行流（主协程）。对于普通工作线程，它一出生就跑调度逻辑，所以主协程就是调度协程。
   - 但主线程（use_caller 线程）不同，它在调用调度器之前，已经在跑 `main` 函数的代码了。如果你直接在 `main` 线程的原始栈上跑死循环，`main` 函数剩下的逻辑就被物理截断了。

2. **建立“调度中转站”**:
   - 我们通过 `new Fiber` 为主线程开辟了一块独立的 1MB 栈空间。
   - **隔离**: `main` 函数的局部变量和进度保存在原始栈；调度器的 `run` 逻辑保存在这 1MB 新栈。
   - **中转**: 当业务协程 `yield` 时，根据非对称模型，它必须跳回“把它 resume 起来的人”。在 `use_caller` 模式下，这个“人”就是 `m_rootFiber`。

3. **实现“随时待命”**:
   - 这样主线程就拥有了“变身”的能力：平时跑 `main` 逻辑，想干活时就 `resume` 进 `m_rootFiber` 变成工人；干完活 `yield` 回来，`main` 函数依然能接上之前的进度继续跑。

**总结**: `new` 出来的调度协程是主线程的“第二人格”。没有它，主线程就无法在保留 `main` 现场的同时，去接管和分发其他业务协程。

##### Q: 在 use_caller 模式下，主线程在 stop() 时被阻塞去跑调度循环，这不也是阻塞吗？
**A**: 是，这确实会阻塞 `main` 线程，但这正是 `Sylar` 极其精妙的 **“性能算盘”**。理解了它，你就能明白为什么高性能框架都爱这么干：

1. **为什么 main 线程“心甘情愿”被阻塞？**
   - 在正常的服务器逻辑中，`main` 函数的生命周期通常是：初始化 -> 创建调度器 -> 添加初始任务（如启动 TCP Server）-> **调用 stop()**。
   - **关键点**: 当执行到 `stop()` 时，`main` 函数其实已经没活干了！
   - **对比**: 
     - **不开启 use_caller**: `main` 线程会卡在 `thread->join()` 上死等子线程结束。此时 `main` 线程是在“内核发呆”，白白浪费了一个 CPU 核心。
     - **开启 use_caller**: `main` 线程不再“死等”，而是化身为一名工人，帮着子线程一起把剩下的几万个协程跑完。
   - **结论**: 这是一种 **“废物利用”**。既然最后都要等，不如在等的时候帮着干点活。

2. **只有 stop() 会阻塞吗？**
   - **是的**。这是工程实现上的重要区分：
   - **start() 函数**: 即使开启了 `use_caller`，`start()` 也是非阻塞的。它只是招好了工人，主线程调完 `start()` 依然可以继续往下跑，去初始化别的业务模块。
   - **stop() 函数**: 它是同步点。它代表老板说：“活儿都派完了，大家加把劲干完咱们就散伙。” 这时候主线程才正式加入战场。

3. **如果我不想让 main 线程干活怎么办？**
   - 如果你有特殊需求（如 `main` 线程需要跑图形界面 GUI 或死循环监控），只需在构造时设为 `false`: `new Scheduler(threads, false)`。这样 `main` 线程永远在外面“看戏”，调度器会完全使用新开的子线程去工作。

**总结：use_caller 的真相**
它是为了 **“压榨单机性能上限”** 而设计的：
- **省内存**: 少开一个内核线程，就省了约 8MB 的系统栈开销。
- **提速度**: 多一个执行流干活，总任务处理得更快。
- **应用场景**: 最适合那种“启动后就一直全速跑，直到关机”的高负载后端服务。

##### Q: 调度器的任务源头是谁？是在哪里提交的？
**A**: 调度器的任务提交（`schedule`）构成了一个动态的“活水系统”，分散在三个关键点：

1. **初始驱动 (main 线程)**: 系统启动时，由 `main` 线程手动提交第一个任务（如启动 TCP Server），这是推动机器转动的第一块骨牌。
2. **逻辑裂变 (业务协程内部)**: 正在运行的协程可以随时调用 `Scheduler::GetThis()->schedule()` 来产生新的并发任务。这使得复杂的并行逻辑（如网页爬虫的多级深度抓取）可以极其自然地展开。
3. **底层回流 (IO 管理器唤醒)**: 当协程因等待 IO 进入 `HOLD` 状态后，它会从任务队列中消失。一旦 IO 事件触发，`IOManager` 会在底层偷偷地将该协程重新 `schedule`进队列，使其“原地复活”。

##### Q: 与传统 Reactor 线程池相比，这种“全员可派活”的模型有什么本质优势？
**A**: 传统的 Reactor 模型通常有严格的“等级森严”制度：主线程发令，子线程干活。子线程想再派活往往非常复杂。协程调度器则彻底打破了这种边界：

1. **去中心化**: 得益于 TLS 维护的调度器指针，任何协程在任何线程都能瞬间变成“生产者”。这种自由度让并发逻辑的编写不再受限于线程身份。
2. **绝对解耦**: 提交任务只是向带锁队列推送一个轻量级对象，不需要同步等待。这消除了传统线程池中常见的“子线程向自己提交任务导致资源死锁”的风险。
3. **极致吞吐**: 这种“自产自销”的裂变能力，配合多线程的主动抢占，确保了 CPU 的每个核心都能在任务高峰期被瞬间填满。

**总结**: 协程调度器将“生产者”和“消费者”的物理界限彻底抹除，使全系统变成了一个高度自治、自驱动的并发工厂。

##### Q: 如果对传统 Reactor 改进一下也支持 TLS，是不是也能实现“全员提交任务”？那协程调度器的优势在哪？
**A**: **技术上完全可以实现**。现代 Reactor 库（如 Muduo）通过 TLS 存储 EventLoop 指针，同样实现了任意线程派活的功能。

然而，协程调度器与“Reactor + TLS”的代差不在于“谁能提交”，而在于任务被提交后的 **“执行形态”**：

1. **状态保持能力 (有栈 vs 无栈)**:
   - **Reactor + TLS**: 提交的是“函数指针”。任务一旦开始，必须跑完。若中途需等待（如 RPC），它无法在原地停下，必须拆分成多个回调函数。
   - **协程调度器**: 提交的是“有栈协程”。任务跑一半发现要等，可以直接 Yield。它能带着所有的**局部变量、函数调用链**原地消失，等数据好了再原地复活。这种“任务具备记忆力”的特性是传统模型无法企及的。

2. **编程范式的跃迁**:
   - **Reactor 模式**: 开发者必须面对“碎片化”的逻辑。维护大量的状态机和上下文对象，开发极其复杂的业务时逻辑极易破碎（回调地狱）。
   - **协程模式**: 实现“同步编程，异步执行”。开发者可以写出连贯的、符合人类直觉的顺序代码，而底层的 TLS 调度器自动处理了所有切换细节。

3. **线程利用率的颗粒度**:
   - **Reactor**: 切换颗粒度是“函数级”。函数不结束，线程不能动。
   - **协程调度器**: 切换颗粒度是“逻辑点级”。只要遇到 IO 或主动 Yield，线程立刻切换。这让 CPU 利用率达到了细原子级，几乎消灭了所有的等待空转。

**深度总结**: TLS 仅仅解决了“找老板”的问题（提交便捷性），但协程解决了“活怎么干”的问题（执行连贯性）。**协程赋予了 TLS 任务以“灵魂（状态保持）”**，让高性能开发从“拼图游戏”变成了“写作文”。

##### Q: 协程调度器的本质是什么？可以理解为将任务拆碎来压榨线程池性能吗？
**A**: **这是一个非常深刻的直觉，但需要微调。** 任务并没有被物理拆碎，而是被赋予了“现场保存”的能力：

1. **物理真相**: 任务确实都在线程中执行。协程没有物理执行力，它只是一份存储在内存里的状态。
2. **“现场保存”代替“任务拆分”**: 
   - 传统的任务是一个死板的函数，一旦阻塞（等 IO），整个线程就陷入内核级睡眠。
   - 协程赋予了任务“主动存档（Yield）”的能力。当逻辑卡住时，它带着调用栈和局部变量原地消失，让出物理线程。
3. **压榨性能的本质**: 
   - 它压榨的是 **“内核态与用户态的边界”**。它让操作系统认为线程一直在干活，从而避免了昂贵的内核上下文切换（微秒级）。
   - 它让任务切换的成本降到了纯内存操作（纳秒级）。

**形象比喻**: 协程调度器就像是一个 **“超级网管”**。他管理着 1000 个玩家（协程）和 4 台电脑（线程）。只要某个玩家的英雄在“回城（等 IO）”，网管就瞬间把该玩家移开，让下一个玩家坐上去。电脑（CPU）的键盘一秒钟都不会停止敲击。

**结论**: 协程是执行上下文的 **“多路复用 (Multiplexing)”**。它不是把任务拆小了，而是把线程忙碌的时间切得更细、填得更满了。

##### Q: 既然协程是为了解决 IO 阻塞，那 IO 到底是在哪里执行的？它不在线程里运行吗？
**A**: 这是一个触及底层真相的好问题。结论是：**IO 的“发起”和“处理”在线程中，但 IO 的“漫长等待”和“数据搬运”是在内核 and 硬件中完成的。**

我们可以将 IO 过程拆解为三个物理阶段：

1. **发起阶段 (线程执行)**:
   - 线程执行系统调用（如 `read`）。CPU 此时还在线程里，负责下达“订单”。
   - **动作**: 告诉内核，“我要读这个文件描述符（fd）的数据”。

2. **执行/等待阶段 (内核与硬件执行 - 核心所在)**:
   - 一旦订单下达，剩下的活儿就跟线程（以及 CPU）没关系了：
   - **网卡/磁盘 (硬件)**: 负责从物理介质中抓取原始电信号。
   - **DMA (直接存储器访问)**: 这是一个硬件小助手，它负责将硬件抓到的数据直接搬运到内存里。**这个过程完全不消耗 CPU 算力。**
   - **内核 (OS)**: 负责管理数据缓冲区、维护协议栈。
   - **此时线程在干嘛？**: 
     - **同步模型**: 线程被内核强行挂起（睡眠），CPU 在那发呆死等。
     - **协程模型**: 线程立即执行 `Yield` 飞走去跑别的协程了。

3. **完成/处理阶段 (线程重新接管)**:
   - 当硬件把数据搬完了，内核会通过信号或 `epoll` 触发。
   - 调度器从 `idle` 协程中感知到事件，通过 `Resume` 唤醒挂起的协程。
   - **线程**重新回到上次停下的位置，开始处理已经在内存里准备好的数据。

**形象对比：快递站模型**
- **同步 IO (老式)**: 你亲自去快递站。快递没到，你就站在窗口死等，快递站的这个窗口就卡死了。
- **异步 IO + 协程 (Sylar 模型)**: 你给快递站留个电话（注册 epoll），回公司接着写代码（Yield）。快递员（硬件/DMA）偷偷把包裹放进柜子（内存）。你收到短信，放下手里的活去拿包裹（Resume）。

**总结**: IO 并没有在线程里“运行”，而是在硬件和内核里“流动”。协程调度器的本质是：**让线程只负责“下单”和“收货”，而把最浪费时间的“等货”过程交给内核，从而实现极高的吞吐效率。**

##### Q: 调度器的核心引擎 `run()` 函数是如何工作的？请拆解其生命阶段.
**A**: `run()` 是每一个调度线程的“灵魂”，它是一个永不停歇的任务处理死循环，可以拆解为四个关键阶段：

1. **身份登记 (Setup)**:
   - 线程启动后，首先将当前调度器指针和“调度协程”指针存入 TLS（线程局部存储）。
   - **意义**: 确保线程内的任何代码都能随时通过 `GetThis()` 找到所属的老大。

2. **去中心化抢活 (Task Selection)**:
   - 线程加锁进入公共任务队列 `m_fibers`。
   - **公平竞争**: 遍历队列，跳过指定了其他线程 ID 的任务，认领属于自己或无主（ID为-1）的任务。
   - **分发本质**: 任务一旦被 `erase` 出队列，分发即宣告完成。这种“主动抢占”模式消除了中心化分发线程的性能瓶颈。

3. **用户态执行与状态回收 (Execution & Recovery)**:
   - 调用 `resume()` 切换进业务协程。此时 `run()` 函数所在栈帧被物理封存，CPU 跳转执行业务。
   - **自动回归**: 业务协程 Yield 或结束后，控制权物理性跳回 `run()` 的下一行。
   - **逻辑处理**: 调度器检查协程返回时的状态（READY/HOLD/TERM），决定是将其重新塞回队列尾部，还是彻底销毁。

4. **上帝之眼 (Idle)**:
   - 若仓库空了，线程不退出也不忙轮询，而是 `resume` 进 `idle_fiber`。
   - **未来预告**: 在 `IOManager` 中，这里将变成 `epoll_wait`。线程会在这里进入深度睡眠，直到网卡数据惊醒它们。

##### Q: 调度器运行期间会创建多少个协程？内存开销如何计算？
**A**: 这是 Sylar 框架最精妙的“算力账单”。协程分为两类：

1. **基础设施协程 (固定开销)**:
   - **每个线程必占**: 1 个主协程（代表线程原始流）+ 1 个空闲协程（跑 idle）+ 1 个回调复用协程（包装函数任务）。
   - **use_caller 线程额外占**: 1 个独立的调度协程（m_rootFiber）。
   - **公式**: 设工作线程为 M，固定协程总数 = $3 \times M + 4$。
   - **结论**: 即使你开 100 个线程，固定开销也就 300 多个协程，内存基准线极低。

2. **业务任务协程 (动态开销)**:
   - **Fiber 任务**: 你手动 `new Fiber` 多少个，就有多少个。
   - **Function 任务 (核心优化)**: **不增加协程数量！** 调度器会利用每个线程自带的“回调复用协程”，通过 `reset()` 机制像换零件一样轮换执行函数。

**深度总结**: 通过 **“栈空间复用 (reset 机制)”**，Sylar 实现了以极少的固定协程（十几个）处理海量（百万级）函数式任务的能力。它压榨的不仅是 CPU 的空闲时间，更是内存的每一寸产值。

##### Q: 在不考虑内存限制的前提下，协程创建得越多跑得就越快吗？
**A**: **完全不是。** 协程数量与系统性能之间遵循一条“先升后降”的倒 U 型曲线。即便内存无限，性能也会撞上物理天花板：

1. **上下文切换的“隐形成本”**: 
   - 切换虽快（纳秒级），但不是零开销。如果创建了百万个 CPU 密集型协程，CPU 会把大量时间浪费在寄存器的“存”与“取”上（swapcontext）。
   - **比喻**: 就像一个工人每写一个字就换一份文件夹，他全天的时间都花在“翻文件夹”上了，真正产出的字数寥寥无几。

2. **调度器的“锁竞争”与“遍历开销”**: 
   - 随着任务队列（m_fibers）变长，多工作线程抢夺同一把互斥锁的冲突会变得剧烈。
   - 在 `run()` 循环中遍历长队列以寻找匹配 thread_id 的任务，会产生 O(N) 的逻辑损耗。

3. **IO 的物理天花板 (核心瓶颈)**: 
   - 协程的价值在于“遮盖 IO 延迟”。如果网卡带宽或磁盘 IOPS 已经占满，再多协程也只能在 HOLD 状态排队。
   - **内核压力**: 过多协程意味着内核 `epoll` 树的节点数激增，每次事件触发的查找与通知开销也会显著增加。

**形象比喻：餐厅模型**
- **CPU 核心** = 厨师；**灶台** = 线程；**协程** = 订单。
- 如果只有 4 个厨师，即便你接了 10 万个订单，同一秒钟也只能炒出 4 盘菜。
- 订单过多时，厨师翻本子记录（调度开销）和洗菜池堵塞（IO 瓶颈）会让上菜速度反而变慢。

**结论**: **并发 (Concurrency)** 不等于 **并行 (Parallelism)**。最优的协程数量是刚好能填满 CPU 的所有空闲碎片，且不产生明显的管理内耗。在工业实践中，必须通过“流量控制”来防止协程爆炸。

##### Q: 架构深度思考：Reactor 模型中主线程负责 Accept，那协程调度器的 use_caller 模式下谁来处理新连接？
**A**: 这是一个从“线程职责绑定”向“协程任务绑定”跃迁的核心设计问题。

1. **职责分配的降维**:
   - **传统 Reactor**: 职责绑定在“线程”上。主线程（Master）是监工，专门负责 Accept；从线程（Worker）是苦力，负责处理 IO。主线程即便闲着也不会去干苦力。
   - **协程调度器**: 职责绑定在“协程”上。我们不再说“哪个线程负责 Accept”，而是创建一个专门的 **“Accept 协程”**。

2. **“Accept 协程”的流转**:
   - 这个协程跑一个死循环，不断调用 `accept()`。
   - 如果没有新连接，它通过 `Yield` 挂起，把 CPU 让给别人。
   - 当监听套接字（listen_fd）有事件触发时，调度器（IOManager）将其重新设为 `READY`。
   - **重点**: 此时调度器中**任何一个空闲的线程**（可能是子线程，也可能是开启了 `use_caller` 的主线程）都可以领走这个“Accept 协程”并执行一次连接处理。

3. **use_caller 的本质**:
   - 开启 `use_caller` 只是意味着主线程也加入到了“任务抢占”的体系中。
   - 它脱掉了“监工”的外套，变成了“全能工人”。如果这一秒没有新连接，它就去处理业务请求（协程 A）；如果下一秒刚好它抢到了“Accept 协程”，它就顺手处理一个新连接。

4. **优势对比**:
   - **去中心化**: 彻底消除了单线程处理新连接的瓶颈。
   - **极致伸缩**: 所有的线程地位对等。在极致高并发下，所有线程都能参与 Accept 抢占；在低负载下，主线程也能干杂活，不会造成 CPU 资源浪费。
   - **编程简化**: 像写同步代码一样写 `while(true) { accept... }`，调度器在底层自动处理了跨线程的负载均衡。

**总结**: 在协程调度器中，**“谁来干活”不再重要，重要的是“活儿就在那里”**。只要监听套接字在 `epoll` 里，任何一个跑在调度器里的线程都是潜在的 Accept 处理器。

---

## IO 模块 (IO Module)

### 1. IO 调度基础：epoll 深度解析
#### 模块作用
`epoll` 是 Linux 下高性能网络编程的“核动力发动机”。它解决了传统 `select/poll` 在处理万级、十万级并发连接时由于“线性扫描”导致的性能崩溃问题。

#### 核心三部曲：epoll 族函数详解

##### (1) epoll_create(int size)
- **作用**: 在内核中创建一个“事件表”对象。
- **返回值**: 
  - 成功：返回一个非负的文件描述符（epfd）。
  - 失败：返回 -1，并设置 errno。
- **代码示例**:
  ```cpp
  int epfd = epoll_create(5000); 
  if (epfd == -1) { /* 处理错误 */ }
  ```
- **注意**: 自 Linux 2.6.8 之后，`size` 参数只要大于 0 即可，内核会自动动态分配内存。返回值必须记得 `close`。

##### (2) epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)
- **作用**: 操作监控中心。告诉它你要“增加 (ADD)”、“修改 (MOD)”还是“删除 (DEL)”对某个文件描述符（fd）的关注。
- **返回值**:
  - 成功：返回 0。
  - 失败：返回 -1，并设置 errno。
- **关键结构体 `epoll_event`**:
  - `events`: 关注的事件类型（如 `EPOLLIN`, `EPOLLOUT`, `EPOLLET`）。
  - `data.ptr`: **【核心技巧】** 这是一个万能指针。在 Sylar 中存入 `FdContext*` 指针。
- **代码示例**:
  ```cpp
  struct epoll_event ev;
  ev.events = EPOLLIN | EPOLLET; // 读事件 + 边缘触发
  ev.data.ptr = fd_ctx_ptr;      // 存入上下文指针
  epoll_ctl(epfd, EPOLL_CTL_ADD, fd, &ev);
  ```

##### (3) epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout)
- **作用**: **“蹲守”事件**。线程执行到这里会进入睡眠（挂起），内核会监控就绪列表，一旦有 fd 就绪，就将其信息拷贝到 `events` 数组中。
- **返回值**:
  - 成功：返回就绪的文件描述符个数。
  - 超时：返回 0。
  - 失败：返回 -1，并设置 errno。

##### 深度理解：epoll 如何“记住”对象？
`epoll_event` 结构体中包含一个关键的联合体 `epoll_data_t`：
```cpp
typedef union epoll_data {
    void    *ptr; // 我们在这里存 FdContext 指针
    int      fd;  // 也可以只存 fd
    uint32_t u32;
    uint64_t u64;
} epoll_data_t;
```

**Sylar 的 O(1) 映射黑科技**：
- **注册时**：我们通过 `epoll_ctl` 将该 fd 关联的 `FdContext*` 上下文对象指针塞进 `data.ptr`。
- **返回时**：`epoll_wait` 并不只是返回 fd，它会原封不动地把我们之前塞进去的 `ptr` 吐出来。
- **优势**：我们不需要通过 fd 去查 Map 或数组来找对象，而是直接从 `events[i].data.ptr` 拿到对象地址。这消除了查找开销，实现了**从内核事件到业务对象的物理级直达**。

- **代码示例**:
  ```cpp
  struct epoll_event events[256];
  // 阻塞等待，内核会将就绪事件填充到 events 数组
  int n = epoll_wait(epfd, events, 256, 5000); 
  
  for (int i = 0; i < n; ++i) {
      // O(1) 拿回注册时绑定的上下文对象
      FdContext* ctx = (FdContext*)events[i].data.ptr;
      // 直接触发 ctx 内部对应的协程任务
  }
  ```

##### (4) pipe(int pipefd[2])
- **作用**: 创建一个单向的数据通道（管道），用于进程或线程间通信。
- **返回值**:
  - 成功：返回 0。
  - 失败：返回 -1，并设置 errno。
- **核心逻辑**:
  - `pipefd[0]`: **读端**。从这里读取数据。
  - `pipefd[1]`: **写端**。往这里写入数据。
  - **特性**: 写入写端的数据会被内核缓存，直到从读端读出。它是**同步**的，如果读端没数据且没设置非阻塞，`read` 会卡住。
- **代码示例**:
  ```cpp
  int fds[2];
  pipe(fds);
  write(fds[1], "T", 1); // 发送唤醒信号
  char c;
  read(fds[0], &c, 1);   // 接收唤醒信号
  ```

### 2. IO 监听的全生命周期：从注册到唤醒
实现 IO 监听并非孤立动作，而是一个由 **用户、IOManager、Linux 内核** 三方协同完成的物理闭环：

#### 第一阶段：注册 (我要看这个 fd)
1. **保存现场**：用户调用 `addEvent(fd, READ, cb)`。IOManager 定位到 `FdContext`，记录回调 `cb`（或当前协程指针）。
2. **告知内核**：执行 `epoll_ctl(ADD/MOD)`。将 fd 挂载到内核红黑树，并订阅特定事件。
3. **挂起协程**：用户协程执行 `Fiber::YieldToHold()`。代码流在这一行“物理断开”，执行权返回调度器跑其他任务。

#### 第二阶段：沉睡 (没活干，等内核踢醒)
1. **进入 Idle**：调度线程发现任务队列空了，自动切换进 `idle` 协程。
2. **阻塞等待**：执行 `epoll_wait()`。线程进入真正的内核级睡眠，不消耗 CPU。此时 Linux 内核在后台接管了监控职责。

#### 第三阶段：触发 (数据到了！)
1. **内核唤醒**：网卡收到数据，内核发现 fd 满足就绪条件，将其移入就绪链表并踢醒阻塞在 `epoll_wait` 的线程。
2. **分发 (Dispatch)**：线程从 `epoll_wait` 返回，通过 `events[i].data.ptr` 瞬间定位到 `FdContext`。
3. **重新排队**：调用 `triggerEvent()`。它内部并不直接运行回调，而是执行 `m_scheduler->schedule(cb/fiber)`。至此，被挂起的协程重新回到了 **“就绪任务队列”**。

#### 第四阶段：执行 (原地复活)
1. **让出权**：`idle` 协程处理完本轮所有就绪事件后执行 `Yield`。
2. **重新调度**：线程回到 `Scheduler::run()` 主循环，发现了刚才被塞进去的 IO 任务。
3. **恢复执行**：调用 `fiber->resume()`。
4. **结果**：用户协程从上次 `YieldToHold()` 的断点处**无缝复活**，继续往下处理业务数据。

**核心逻辑本质**：`epoll_wait` 在这里充当了协程的 **“外部闹钟”**。它让处于暂停状态的逻辑，能够因为一个硬件事件而重新被系统感知并调度。

#### 遇到的问题

##### Q: tickle() 为什么要用 pipe 管道？（唤醒机制深度解析）
**A**: **为了叫醒“正在睡觉”的 epoll_wait**。
这是一个非常经典的设计模式，被称为 **self-pipe trick**。

1. **睡眠场景**: 当没有网络 IO 任务时，调度线程会执行 `idle` 协程，最终卡在 `epoll_wait` 上进入内核态睡眠，以节省 CPU。
2. **突发任务**: 此时，主线程突然调用 `schedule(cb)` 塞进来一个普通函数任务。
3. **僵局**: 由于这个任务不是 IO 任务，`epoll_wait` 感知不到任何套接字变化，它会继续睡下去（比如睡 5 秒）。这意味着你的任务被延迟了 5 秒才执行！
4. **破局（Tickle）**: 
   - 我们在 `IOManager` 初始化时，创建一对 `pipe` 管道。
   - 把读端 `m_tickleFds[0]` 注册到 `epoll` 中，监听它的 `EPOLLIN`（可读）事件。
   - **动作**: 当 `schedule()` 发现需要唤醒线程时，调用 `tickle()` 往管道写端 `m_tickleFds[1]` 随便写一个字符（如 'T'）。
   - **结果**: 内核瞬间发现管道读端有数据了，于是 `epoll_wait` 立即返回。线程醒来，退出 `idle`，回到 `run` 循环，第一时间处理掉刚才塞进来的新任务。

**总结**: `pipe` 在这里不传递业务数据，它只是一个**跨越内核态的“拍肩”动作**。

##### Q: IOManager 是否“隐藏”了传统 Reactor 中的 epoll 循环？
**A**: **是的，这正是协程调度器最核心的架构魔术。**

1. **循环位置的“深度潜伏”**:
   - **传统 Reactor**: `epoll_wait` 是显式的“老大”。它位于 `main` 函数或 `EventLoop` 的最外层，像一个严厉的监工，控制着所有事件的分发。
   - **Sylar IOManager**: 循环被“藏”在了 `idle` 协程内部。它不再是程序的中心，而变成了调度器在“走投无路（没活干）”时才去执行的一个低优先级任务。

2. **“身份倒置”的设计精髓**:
   - **在 IOManager 中，Scheduler::run() 才是真正的上帝**。它只关心一件事：任务队列里有没有活。
   - 线程处于一种 **“按需切换”** 的动态身份中：
     - **Worker 身份**: 只要队列里有任务，线程就在 `run()` 循环里疯狂忙碌，完全不理会 `epoll`。
     - **Reactor 身份**: 只有当队列彻底空了，线程才会通过 `idle` 协程进入 `epoll_wait` 睡眠。
   - **意义**: 这种设计让 CPU 资源 100% 优先供给计算任务，IO 监听只占用了 CPU 的“垃圾时间”。

3. **执行流的“发牌”与“解耦”**:
   - **传统 Reactor**: `epoll_wait` 醒了之后必须立即在当前循环里执行完所有回调。如果某个回调慢了，整个 Reactor 就卡住了。
   - **IOManager**: `idle` 协程醒了之后只负责 **“发牌”**。它把就绪的协程往任务队列一扔，然后立刻 `Yield` 让出控制权。
   - **结果**: 具体的 IO 业务逻辑（协程）会回到 `Scheduler::run()` 中被公平地调度。这种“监听”与“执行”的物理分离，彻底解决了传统 Reactor 容易被耗时回调卡死的痛点。

**总结**: `IOManager` 通过将 `epoll` 循环“协程化”，实现了 **“计算与 IO 的大一统”**。对开发者而言，循环消失了，取而代之的是连续的、同步的编程逻辑。

##### Q: 为什么在协程中绝对不能调用系统原生的 sleep()？
**A**: 这是协程框架初学者最容易掉进去的“深坑”。理解这个问题，需要区分 **“执行流挂起”** 与 **“线程阻塞”** 的本质区别：

1. **一人停，全家停 (Thread-level Blocking)**:
   - 系统原生的 `sleep()` 是内核提供的功能。它会让整个 **“内核线程”** 进入睡眠状态。
   - 在协程框架中，一个线程往往承担着成千上万个协程的运行任务。
   - 如果你在协程 A 中调了原生 `sleep()`，内核会认为这个线程不需要 CPU 了，从而将其挂起。
   - **后果**: 该线程上的协程 B、C、D 以及负责唤醒的 `idle` 逻辑全部被物理卡死。整个系统会表现为“瞬间瘫痪”。

2. **协程睡眠的正确姿势 (Coroutine-level Yielding)**:
   - 理想的睡眠应该是：协程 A 说“我要睡 3 秒”，然后它通过 `Yield` 把 CPU 让出来给协程 B 跑。等到 3 秒钟时间一到，调度器再自动把它唤醒。
   - **实现方案**: 
     - 1. **Timer (定时器)**: 框架需要一个定时任务管理器。
     - 2. **自动唤醒**: 协程睡眠前向 Timer 注册一个任务，到时后执行 `schedule(A)`。
     - 3. **挂起**: 协程执行 `YieldToHold()`。

3. **未来预告：Timer 与 Hook 模块**:
   - 我们接下来的任务就是实现 **Timer (定时器)**，让 `IOManager` 具备精准的时间控制能力。
   - 最终，我们将通过 **Hook (钩子) 技术**，在底层把原生的 `sleep` 替换成我们自定义的协程版 `sleep`。
   - **效果**: 开发者依然写 `sleep(1)`，但代码在运行时会自动变成“注册定时器 + Yield”的非阻塞操作，实现无感的高性能并发。

**总结**: 协程框架的生命线是 **“不阻塞物理线程”**。任何会导致线程进入内核睡眠的操作（如原生 `sleep`、阻塞 `read/write`）都是协程系统的天敌。

---

## 定时器模块 (Timer Module)

### 1. Timer (精准闹钟管理中心)
#### 类作用
系统的“核心时钟”。它负责管理海量的定时任务，通过高精度的毫秒级计时，为协程提供时间感知能力（如延迟执行、超时控制、定时心跳等）。

#### 为什么需要定时器？（核心痛点）
1. **实现“非阻塞”协程睡眠**: 
   - 解决协程内无法调用系统 `sleep()` 的难题。通过“注册定时任务 + 挂起协程 + 到期唤醒”实现逻辑上的睡眠，而不阻塞物理线程。
2. **处理网络请求超时**: 
   - 防止由于对端无响应导致的协程死等。为每个网络 IO 操作挂载一个闹钟，时间到期若未完成则强制中断并报错。
3. **驱动 IO 调度器的精准阻塞**: 
   - `IOManager` 的 `epoll_wait` 需要根据最近一个定时器的剩余时间来决定睡多久，既保证了实时性，又避免了空转。

#### 设计核心
- **高性能容器**: 采用 `std::set` (平衡二叉树) 存储定时器，利用其自动排序特性实现最小堆逻辑。
  - **插入复杂度**: $O(\log N)$。
  - **获取最近任务**: $O(1)$（即 `begin()` 元素）。
- **条件定时器 (Condition Timer)**: 
  - 支持绑定 `weak_ptr`。在任务触发前检查对象是否存活，防止因对象销毁导致的回调崩溃。
- **时间翻转检测 (Clock Rollover)**: 
  - 自动识别系统时间被手动调后的异常情况，强制让定时器过期，确保系统逻辑的稳定性。

#### 架构地位
定时器管理器 `TimerManager` 通常被 `IOManager` 继承。这使得 `IOManager` 能够将“IO 事件”与“时间事件”统一在 `idle` 协程中进行闭环处理。

#### 深度解析：时间与 IO 的统一
##### Q: 协程在哪里“睡”了？epoll_wait 为何是唯一的睡眠出口？
**A**: 在协程调度器中，`epoll_wait` 的 `timeout` 参数是连接“时间”与“IO”的枢纽：
1. **阻塞即睡眠**: 调用 `epoll_wait` 时，内核会将线程挂起。这在物理上实现了“不消耗 CPU 的睡眠”。
2. **唤醒的主动权**:
   - **无定时器时**: 若设为 `-1`（永久阻塞），唤醒完全依赖外部 IO 信号（被动）。
   - **有定时器时**: `IOManager` 会向 `TimerManager` 询问最近一个任务的到期时间，并将其设为 `timeout`。
3. **结果**: 线程变成了“能够自我修正的闹钟”。即使没有 IO 数据，时间一到，内核也会准时踢醒线程，让其回到用户态处理到期的定时任务。

##### Q: 加了定时器比永久阻塞（timeout = -1）的优势在哪里？
**A**: **解决任务“饥饿”问题。**
- **场景**: 假设你提交了一个“1秒后打印 Log”的任务，但此时网络非常安静（没有 IO）。
- **永久阻塞的困境**: 线程会死睡在 `epoll_wait` 里。虽然 1 秒钟很快就过去了，但由于没有 IO 事件触发，线程醒不来，那个打印 Log 的任务会被无限期延迟（饥饿）。
- **精准阻塞的破局**: 线程执行 `epoll_wait(timeout = 1000ms)`。1 秒后，内核准时唤醒线程。`epoll_wait` 返回 0，线程通过 `listExpiredCb()` 抓取到期任务并 `schedule` 执行。
- **结论**: 定时器让调度器从单纯的“听天由命（等数据）”进化为“主动出击（控时间）”。

##### Q: 定时阻塞 (timeout = ms) 下，如果 IO 提前到了会怎样？
**A**: **立即返回，绝不等待。**
- **误区**: 认为设了 5 秒超时，就非得等到 5 秒结束才醒。
- **真相**: `timeout` 参数的本质是 **“最大允许睡眠时间”**。
- **内核行为**: 内核会同时监控“文件描述符状态”和“内核定时器”。只要 **其中任何一个** 满足条件（数据到了 OR 时间到了），`epoll_wait` 就会瞬间结束阻塞并返回。
- **意义**: 这种机制完美实现了 **“有活干秒回，没活干准时醒”** 的平衡。

##### Q: 永久阻塞（-1）、定时阻塞（ms）和忙轮询（0）在 CPU 占用上有何区别？
**A**: 这三者的区别仅仅体现在 `epoll_wait` 的第四个参数上，代表了对 **“响应延迟”** 与 **“系统功耗”** 的不同取舍：

1. **永久阻塞 (timeout = -1)**:
   - **行为**: 线程彻底让出 CPU，进入内核等待队列。
   - **响应**: 只能靠外部 IO 事件。
   - **评价**: 最省电，但容易导致内部产生的纯计算/定时任务“饥饿”。

2. **定时阻塞 (timeout = ms)**:
   - **行为**: 线程让出 CPU，但由内核定时器担保在指定时间后强制唤醒。
   - **响应**: IO 事件 **或** 时间到期。
   - **评价**: 兼顾了“低功耗”与“高实时性”，是 Sylar 等高性能框架的 **标配选择**。

3. **忙轮询 (timeout = 0)**:
   - **行为**: 线程 **绝不让出 CPU**。`epoll_wait` 扫一眼内核状态后立即返回。
   - **为何存在？**: 当线程进入睡眠（-1 或 ms）再被唤醒时，会涉及“上下文切换”，产生微秒级的调度延迟（所谓的“起床气”）。
   - **价值**: 在 **极致追求低延迟** 的领域（如高频交易、顶级游戏引擎），通过占满 100% CPU 来换取那几微秒的零延迟响应。
   - **评价**: 对普通应用而言是严重的资源浪费，在通用框架中通常被禁用。

| 模式 | epoll_wait 参数 | 让出 CPU | 唤醒源 | 核心价值 |
| :--- | :--- | :--- | :--- | :--- |
| **永久阻塞** | `-1` | 是 | 仅 IO | 纯 IO 驱动，最省电 |
| **忙轮询** | `0` | **否** | 无 (即时返回) | **极致低延迟 (微秒级抢时)** |
| **定时器模式** | `ms` | 是 | IO + 时间 | **计算与 IO 的大一统** |

**结论**: `epoll_wait` 是协程框架的 **“呼吸孔”**。通过精准计算 `ms` 参数，我们让线程能够“按需呼吸”——既能通过睡眠省电，又能通过准时醒来处理任务。

### 2. IOManager 的定时器集成升级
当 `TimerManager` 被集成进 `IOManager` 后，整个系统完成了从“IO 监听器”向“全能调度中心”的质变。

#### (1) 继承关系的质变
- **结构**: `class IOManager : public Scheduler, public TimerManager`
- **意义**: 这种多重继承让 `IOManager` 物理上持有了定时器堆（`std::set`）和相关的读写锁。从此，`IOManager` 不仅仅是一个“跑任务的”，更是一个“懂时间的”管家。

#### (2) idle 调度逻辑的进化 (核心心脏)
`idle()` 协程内部发生了三处质变，实现了“时间”与“IO”的任督二脉打通：

1.  **计算精准睡眠**:
    - 每次进入 `epoll_wait` 前，调用 `getNextTimer()`。
    - **逻辑**: 动态计算距离最近一个任务到期还有多久，将其作为 `timeout` 传给内核。
    - **结果**: 解决了“盲目睡眠”问题，保证了线程在没有 IO 时也能准时醒来。
2.  **处理过期任务**:
    - `epoll_wait` 返回后，第一时间调用 `listExpiredCb()`。
    - **逻辑**: 将所有到期的闹钟回调函数取出，通过 `schedule()` 批量投入就绪队列。
    - **意义**: 定时任务现在拥有了与 IO 事件同等的“一等公民”调度地位。
3.  **停止条件的严谨化**:
    - 只有满足：**[Scheduler要求停] && [没有待处理IO] && [没有剩余定时器]**，`idle` 才会真正退出。

#### (3) 响应式唤醒：onTimerInsertedAtFront
- **逻辑**: 重写该虚函数，内部直接调用 `tickle()`。
- **作用**: 解决了"早起闹钟"问题。如果当前 `epoll_wait` 正打算睡 10 秒，但用户在 1 秒时新加了一个 2 秒后过期的任务，该机制会通过管道立即踢醒线程，强制其重新计算睡眠时间，确保新任务不延误。

---

## Hook 模块 (Hook Module)

### 1. Hook 模块基础
#### 模块作用
系统的"魔法转换器"。通过 Hook 系统的 IO 和睡眠函数，将阻塞调用转换为非阻塞 + 协程调度，实现"同步编程，异步执行"。

#### 设计理念
Hook 模块是 Sylar 框架的核心魔法，它使得：
1. **透明化**: 现有的同步代码无需修改即可获得协程化能力
2. **统一接口**: 标准的 POSIX 函数自动转换为异步
3. **性能提升**: 避免阻塞物理线程，提升并发能力
4. **编程简化**: 像写同步代码一样写异步程序

#### 设计要点
- **函数指针保存**: 使用 `dlsym(RTLD_NEXT, ...)` 保存原始函数指针
- **条件 Hook**: 通过 `thread_local bool t_hook_enable` 控制是否启用
- **睡眠类函数**: sleep/usleep/nanosleep → 定时器 + yield
- **IO 类函数**: 检查 FdCtx，EAGAIN 时注册到 IOManager + yield

#### 遇到的问题
##### Q: hook.h 中每个系统函数前面的 typedef 是什么意思？
**A**: 这是**函数指针的 typedef**，用于定义函数指针类型。

**语法拆解**：
```cpp
// 原始函数类型
unsigned int sleep(unsigned int seconds);

// 函数指针定义
unsigned int (*func_ptr)(unsigned int seconds);

// typedef 语法（把 (*name) 提到前面）
typedef unsigned int (*sleep_fun)(unsigned int seconds);
//                  ^^^^^^^^^  类型名
```

**为什么要这样写？**

目的：保存原始系统函数的地址，以便在 Hook 函数中调用。

```cpp
// ========== hook.h ==========
// 1. 定义函数指针类型
typedef unsigned int (*sleep_fun)(unsigned int seconds);
// 2. 声明函数指针变量（指向原始函数）
extern sleep_fun sleep_f;

// ========== hook.cc ==========
// 3. 初始化：保存系统原始函数地址
sleep_f = (sleep_fun)dlsym(RTLD_NEXT, "sleep");

// 4. 定义 Hook 函数（同名的 sleep）
unsigned int sleep(unsigned int seconds) {
    if (!t_hook_enable) {
        return sleep_f(seconds);  // 调用原始函数
    }
    // ... Hook 逻辑：协程化
}
```

**形象比喻**：
- 系统的 `sleep` 是旧锁
- 我们的 `sleep` 是新锁（Hook 版本）
- `sleep_f` 保存旧锁地址，让我们在新锁中还能调用旧锁

**完整流程示意**：
```cpp
unsigned int read(int fd, void *buf, size_t count) {
    // 1. 先尝试读取
    ssize_t n = read_f(fd, buf, count);  // 调用原始的 read

    // 2. 如果需要等待，就让出 CPU
    if (n == -1 && errno == EAGAIN) {
        Fiber::YieldToHold();
        // 3. 被唤醒后再次尝试读取
        n = read_f(fd, buf, count);
    }

    return n;
}
```

**总结**：
- `typedef` 定义了一个函数指针类型 `sleep_fun`
- `sleep_f` 是这种类型的变量，用于保存系统原始的 `sleep` 函数地址
- 通过 `sleep_f` 可以在 Hook 函数中调用原始系统函数

**类比**：
- `int* p` - p 是指向 int 的指针
- `sleep_f` - sleep_f 是指向函数的指针
- `typedef unsigned int (*sleep_fun)(...)` - 定义函数指针类型，类似 `typedef int* int_ptr`

##### Q: Hook 模块是如何实现"同名替换"系统函数的？
**A**: 这是通过 **链接器符号劫持** 实现的。

**原理**：
1. **定义同名函数**: 我们定义了 `unsigned int sleep(unsigned int seconds)`，与系统函数同名
2. **优先级**: 当程序中有多个同名符号时，链接器会选择**先遇到的**那个
3. **编译顺序**: 如果我们的 hook.cc 先被链接，那么所有的 `sleep` 调用都会跳到我们的函数

**完整流程**：
```cpp
// ========== 编译链接阶段 ==========
// 1. 编译 hook.cc，生成我们的 sleep 函数符号
// 2. 链接时，hook.o 在 libc 之前被链接
// 3. 所有代码中的 sleep 调用都被解析到我们的 sleep 函数

// ========== 运行时初始化 ==========
// 4. 在程序启动时（通过全局变量构造），调用 hook_init()
// 5. hook_init() 使用 dlsym(RTLD_NEXT, "sleep") 找到系统真正的 sleep
// 6. 将地址保存到 sleep_f 变量中

// ========== 运行时调用 ==========
// 7. 用户代码调用 sleep(1)
// 8. 实际执行的是我们的 sleep 函数
// 9. 我们可以根据需要调用 sleep_f(1)（原始函数）或实现自己的逻辑
```

**RTLD_NEXT 的作用**：
```cpp
sleep_f = (sleep_fun)dlsym(RTLD_NEXT, "sleep");
//              ^^^^^^^^^^
//              RTLD_NEXT 表示：在当前搜索顺序之后查找
//              也就是找到系统 libc 中的 sleep 函数
```

**为什么不会死循环？**
```cpp
unsigned int sleep(unsigned int seconds) {
    if (!t_hook_enable) {
        return sleep_f(seconds);  // ✅ 直接调用函数指针，不会触发 Hook
    }
    // ...
}
```

因为 `sleep_f` 是函数指针，直接调用它不会触发符号解析，所以不会死循环。

##### Q: 为什么要用 `extern "C"` 包裹这些声明？
**A**: 为了 **C/C++ 混合链接**。

**问题背景**：
- 系统函数（`sleep`, `read` 等）是 **C 函数**
- C++ 编译器会对函数名进行 **名称修饰（Name Mangling）**，导致链接时找不到系统的 C 函数

**extern "C" 的作用**：
```cpp
extern "C" {
    typedef unsigned int (*sleep_fun)(unsigned int seconds);
    extern sleep_fun sleep_f;
}

// 等价于告诉编译器：
// "这些函数名不要进行 C++ 的名称修饰，保持 C 语言的原样"
```

**名称修饰对比**：
```cpp
// C++ 编译器可能生成这样的符号：
// _Z5sleepj  (mangled name)

// C 编译器生成的符号：
// sleep      (original name)

// 系统库中的符号是 "sleep"，所以我们必须用 extern "C" 匹配
```

**如果我们不用 extern "C"**：
```cpp
// ❌ 错误：C++ 会修饰函数名
typedef unsigned int (*sleep_fun)(unsigned int seconds);
extern sleep_fun sleep_f;  // 符号可能是 _Z7sleep_fj

// 链接时会报错：undefined reference to 'sleep'
// 因为系统库中的符号是 'sleep'，而不是 '_Z7sleep_fj'
```

**总结**：
- `extern "C"` 告诉编译器："用 C 语言的规则处理这些函数名"
- 这样才能正确链接到系统 libc 中的 C 函数

### 2. Hook 函数实现详情

#### 2.1 初始化机制
- **`_HookIniter`**：通过全局静态对象在程序启动时自动初始化
- **`dlsym(RTLD_NEXT, #name)`**：获取系统原始函数指针并保存
- **`t_hook_enable`**：线程局部变量，控制当前线程 Hook 开关
- **`is_hook_enable()` / `set_hook_enable()`**：查询/设置 Hook 开关

#### 2.2 睡眠函数（已实现）

| 函数 | Hook 行为 |
|------|----------|
| `sleep(seconds)` | 调用 `IOManager::addTimer()` 添加定时任务，然后 `Fiber::YieldToHold()` 让出协程，定时器到期后自动唤醒 |
| `usleep(usec)` | 同上，转换为毫秒后添加定时器 |
| `nanosleep(req, rem)` | 同上，支持纳秒级精度 |

**逻辑**：
```cpp
if (!is_hook_enable()) {
    return sleep_f(seconds);  // 直接调用原始函数
}
// 添加定时器，让出协程，定时器到期后自动唤醒
iom->addTimer(seconds * 1000, std::bind(&Scheduler::schedule, iom, fiber));
Fiber::YieldToHold();
```

#### 2.3 Socket 创建连接函数（未实现）

| 函数 | 状态 | 计划实现 |
|------|------|---------|
| `socket(domain, type, protocol)` | ❌ 未实现 | 需要创建 socket 后自动设置为非阻塞，并创建 FdCtx |
| `connect(sockfd, addr, addrlen)` | ❌ 未实现 | 需要支持异步连接，通过 IOManager 注册写事件等待连接完成 |
| `accept(s, addr, addrlen)` | ❌ 未实现 | 需要支持异步接受连接，通过 IOManager 注册读事件等待新连接 |

**占位说明**：这些函数已在 hook.h 中声明，但在 hook.cc 中暂无实现。

#### 2.4 读函数（已实现）

| 函数 | Hook 行为 |
|------|----------|
| `read(fd, buf, count)` | 调用 `do_io()` 处理读事件和 `SO_RCVTIMEO` 超时 |
| `readv(fd, iov, iovcnt)` | 调用 `do_io()` 处理读事件和 `SO_RCVTIMEO` 超时 |
| `recv(sockfd, buf, len, flags)` | 调用 `do_io()` 处理读事件和 `SO_RCVTIMEO` 超时 |
| `recvfrom(sockfd, buf, len, flags, src_addr, addrlen)` | 调用 `do_io()` 处理读事件和 `SO_RCVTIMEO` 超时 |
| `recvmsg(sockfd, msg, flags)` | 调用 `do_io()` 处理读事件和 `SO_RCVTIMEO` 超时 |

**通用逻辑**（`do_io` 模板函数）：
1. 检查 Hook 是否启用，FdCtx 是否有效，是否是 socket，用户是否设置非阻塞
2. 调用原始函数，如果返回 EAGAIN/EINTR，则在 IOManager 中注册读事件
3. 调用 `Fiber::YieldToHold()` 让出协程
4. IO 就绪后被唤醒，重试读取操作
5. 支持超时控制（通过 `SO_RCVTIMEO` 选项设置）

#### 2.5 写函数（已实现）

| 函数 | Hook 行为 |
|------|----------|
| `write(fd, buf, count)` | 调用 `do_io()` 处理写事件和 `SO_SNDTIMEO` 超时 |
| `writev(fd, iov, iovcnt)` | 调用 `do_io()` 处理写事件和 `SO_SNDTIMEO` 超时 |
| `send(sockfd, msg, len, flags)` | 调用 `do_io()` 处理写事件和 `SO_SNDTIMEO` 超时 |
| `sendto(sockfd, msg, len, flags, to, tolen)` | 调用 `do_io()` 处理写事件和 `SO_SNDTIMEO` 超时 |
| `sendmsg(sockfd, msg, flags)` | 调用 `do_io()` 处理写事件和 `SO_SNDTIMEO` 超时 |

**逻辑**：同读函数，但注册的是写事件（`IOManager::WRITE`），超时使用 `SO_SNDTIMEO`。

#### 2.6 控制函数（已实现）

| 函数 | Hook 行为 |
|------|----------|
| `close(fd)` | 先调用 `IOManager::cancelAll(fd)` 取消所有事件，再从 `FdManager` 中删除 FdCtx，最后调用原始 `close()` |
| `fcntl(fd, cmd, ...)` | 处理 `F_SETFL`：检测 `O_NONBLOCK` 标志并更新 FdCtx 的 `m_userNonblock`；处理 `F_GETFL`：根据系统非阻塞状态调整返回值 |
| `ioctl(fd, FIONBIO, ...)` | 处理 `FIONBIO` 命令：设置/清除非阻塞标志，并更新 FdCtx 的 `m_userNonblock` |
| `getsockopt(sockfd, level, optname, ...)` | 直接调用原始函数，无特殊处理 |
| `setsockopt(sockfd, level, optname, ...)` | **特殊处理** `SO_RCVTIMEO` 和 `SO_SNDTIMEO`：将超时时间保存到 FdCtx 中，由框架管理，不传递给系统 |

#### 2.7 辅助函数

| 函数 | 状态 | 说明 |
|------|------|------|
| `connect_with_timeout(fd, addr, addrlen, timeout_ms)` | ✅ 已实现 | 带超时的 connect 函数，用于异步连接场景 |

### 3. Hook 生效机制

#### 概述
Hook 模块的生效并非简单的"开关"模式，而是采用**双重条件判断**机制，确保 Hook 功能在合适的时机自动启用。

#### 生效条件
Hook 功能生效需要同时满足以下两个条件：

1. **Hook 开关已启用**：`is_hook_enable() == true`
   - 通过 `set_hook_enable(true/false)` 手动控制
   - 默认值为 `false`
   - 使用 `thread_local` 存储，每个线程独立

2. **当前在线程调度器中**：`IOManager::GetThis() != nullptr`
   - 表示当前代码正在 IOManager 的工作线程中执行
   - 这是**自动启用 Hook 的关键条件**

#### 关键代码分析

```cpp
// hook.cc 中的典型判断逻辑
if(!sylar::is_hook_enable()) {
    return hook_func(args);  // Hook 未启用，直接调用原始函数
}

sylar::IOManager* iom = sylar::IOManager::GetThis();
if(iom) {
    // 在 IOManager 线程中，执行 Hook 逻辑
    // ...
} else {
    // 不在 IOManager 线程中，调用原始函数
    return hook_func(args);
}
```

#### 两种使用方式

**方式一：手动控制（显式调用 set_hook_enable）**
```cpp
sylar::set_hook_enable(true);
sleep(1);  // 确保 Hook 生效
sylar::set_hook_enable(false);
```

**方式二：自动管理（推荐，利用 IOManager）**
```cpp
sylar::IOManager iom(1, true, "Test");

iom.schedule([]() {
    // 在 IOManager 线程中执行
    sleep(1);  // GetThis() != nullptr，Hook 自动生效！
});
```

#### GetThis() 的生效时机（重要）

**核心原理**：`GetThis()` 返回的是当前线程关联的 Scheduler 指针，这个指针在线程进入 `Scheduler::run()` 函数时被设置，在线程整个生命周期内保持有效。

**时间线示意**：
```
线程创建
    │
    ├──> 进入 Scheduler::run()
    │       │
    │       ├──> setThis() ← 在这里设置 t_scheduler = this
    │       │
    │       └──> while(true) 调度循环
    │               ├── 执行 IOManager 的协程     ← GetThis() != nullptr ✓
    │               ├── 空闲等待（idle）          ← GetThis() != nullptr ✓
    │               ├── 执行用户代码              ← GetThis() != nullptr ✓
    │               └── 用户代码中调用 IO 函数    ← GetThis() != nullptr ✓
    │
    └──> 线程退出（t_scheduler 被清空）
```

**关键代码**：
```cpp
// scheduler.cc
void Scheduler::run() {
    setThis();  // ← 进入 run() 立即设置，整个 run() 期间有效

    while(true) {
        // 无论在循环的哪个位置
        // GetThis() 都会返回当前 IOManager 指针
        // Hook 都会自动生效！
    }
}
```

**重要结论**：
- ✅ **在 IOManager 工作线程中，任何代码调用 IO 函数都会被 Hook**
- ✅ **无需手动调用 `set_hook_enable()`**
- ✅ **不仅限于协程内部，协程外的调度逻辑同样生效**

这也是为什么推荐使用 IOManager 的原因：**只要把代码放入 IOManager 调度，Hook 就自动生效，完全透明**。

#### use_caller=true 时主线程的特殊情况

当 `use_caller=true` 时，主线程也作为工作线程使用，但其 `GetThis()` 的设置时机与子线程不同：

**时间线对比**：
```cpp
int main() {
    // ============ 主线程 ============
    sylar::IOManager iom(1, true, "Test");  // use_caller=true

    // 1. 构造函数中已执行 t_scheduler = this
    // 2. 此时主线程 GetThis() 已经非空！
    sleep(1);  // ✓ Hook 自动生效

    iom.schedule([]() {
        sleep(1);  // 子线程中也生效
    });

    iom.stop();  // 3. 主线程此时才进入 run()
}
```

**关键代码位置**：
```cpp
// scheduler.cc 构造函数第 34 行
if (use_caller) {
    t_scheduler = this;  // ← 主线程在构造时就设置好了
    // ...
}
```

**主线程 vs 子线程对比**：

| 线程类型 | GetThis() 设置时机 | 进入 run() 时机 | Hook 生效时机 |
|---------|-------------------|----------------|---------------|
| 主线程 (use_caller=true) | 构造函数中 | stop() 调用时 | **构造后立即生效** |
| 子线程 | run() 入口 | 线程启动后立即 | 进入 run() 后生效 |

**实际应用示例**：
```cpp
// test_hook.cc 中的用法
sylar::IOManager iom(1, true, "HookTest");  // use_caller=true

// 在主线程中直接测试 Hook 开关
test_hook_switch();  // 这是在主线程中执行的

// 然后在 IOManager 中调度其他测试
iom.schedule(test_sleep);
iom.schedule(test_pipe_io);
```

**重要提示**：
- `use_caller=true` 的主要目的是让主线程参与调度
- 但副作用是：**构造完成后，主线程的 `GetThis()` 就非空了**
- 这意味着主线程在 `stop()` 之前的任何 IO 函数调用都会被自动 Hook

#### 如何控制 Hook 行为

如果不想让某些 IO 操作被 Hook，有以下几种方式：

**方式一：关闭线程级 Hook 开关**
```cpp
// 只影响当前线程
sylar::set_hook_enable(false);
```

**方式二：设置 fd 为非阻塞（fd 级控制，推荐）**
```cpp
// 只影响特定 socket，不影响其他 fd
int flags = fcntl(sockfd, F_GETFL, 0);
fcntl(sockfd, F_SETFL, flags | O_NONBLOCK);
// 之后这个 sockfd 的 IO 操作不会被 Hook
```

**方式三：不在 IOManager 线程中执行**
```cpp
// 在普通线程中执行，GetThis() 返回 nullptr
std::thread t([]() {
    write(fd, buf, len);  // 不会被 Hook
});
```

**设计理念**：
```cpp
// hook.cc 第 147 行的判断逻辑
if (!ctx || ctx->isClose() || !ctx->isSocket() || ctx->getUserNonblock()) {
    return fun(fd, args...);  // 不 Hook，直接调用原始函数
}
```

- 用户主动设置 `O_NONBLOCK` = "我知道我在做非阻塞 IO"
- 框架不应该再 Hook，直接调用原始函数
- 这是**fd 级别的细粒度控制**，比线程级开关更灵活

**实际应用场景**：
```cpp
// 某个第三方库需要自己管理 IO，不想被 Hook
int lib_fd = socket(...);
fcntl(lib_fd, F_SETFL, O_NONBLOCK);  // 标记为用户管理
// 之后该库的所有 IO 操作都不会被 Hook 干扰
```

#### 为什么要双重条件？

1. **灵活性**：通过 `is_hook_enable()` 提供手动控制能力
2. **自动化**：通过 `IOManager::GetThis()` 实现协程调度器内的自动 Hook
3. **安全性**：避免在非协程环境下错误地使用 Hook 逻辑

#### 实际应用场景

| 场景 | is_hook_enable | GetThis() | Hook 是否生效 |
|------|----------------|-----------|---------------|
| 主线程创建 Socket | false | nullptr | ❌ 不生效 |
| IOManager 协程中 sleep | false | 非空 | ✅ **生效**（自动） |
| 手动 set_hook_enable(true) | true | nullptr | ✅ 生效（手动） |
| IOManager + 手动 enable | true | 非空 | ✅ 生效（双重确认） |

#### 最佳实践建议

1. **推荐使用方式二**：让 IOManager 自动管理 Hook，无需手动调用 `set_hook_enable()`
2. **测试验证**：参考 `tests/test_hook.cc` 中的测试用例
3. **注意事项**：确保在 IOManager 的调度上下文中调用 IO 函数

---
